import os
import google.generativeai as genai
from dotenv import load_dotenv
import re
from datetime import datetime, timedelta
import json
import csv
import logging
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from constants import NO_TRANSLATE_TERMS, DEFAULT_ABBR_DICT
from typing import Dict, List, Optional

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Google API í‚¤ ì„¤ì • (ì„ íƒì‚¬í•­)
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY') or os.getenv('GEMINI_API_KEY')
if GOOGLE_API_KEY:
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
        model = genai.GenerativeModel('gemini-2.5-flash-lite')
        GEMINI_AVAILABLE = True
    except Exception as e:
        print(f"GEMINI ì„¤ì • ì‹¤íŒ¨: {e}")
        GEMINI_AVAILABLE = False
        model = None
else:
    GEMINI_AVAILABLE = False
    model = None

# NOTAM ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (ì•„ì´ì½˜ê³¼ ìƒ‰ê¹” í¬í•¨)
NOTAM_CATEGORIES = {
    'RUNWAY': {
        'keywords': ['runway', 'rw', 'í™œì£¼ë¡œ', 'ì°©ë¥™', 'ì´ë¥™', 'landing', 'takeoff'],
        'q_codes': ['Q) RW', 'Q) RWY'],
        'icon': 'ğŸ›¬',
        'color': '#dc3545',  # ë¹¨ê°„ìƒ‰ (ìœ„í—˜/ì¤‘ìš”)
        'bg_color': '#f8d7da'
    },
    'TAXIWAY': {
        'keywords': ['taxiway', 'tw', 'twy', 'íƒì‹œì›¨ì´', 'ìœ ë„ë¡œ', 'movement area'],
        'q_codes': ['Q) TW', 'Q) TWY'],
        'icon': 'ğŸ›£ï¸',
        'color': '#fd7e14',  # ì£¼í™©ìƒ‰
        'bg_color': '#fff3cd'
    },
    'APRON': {
        'keywords': ['apron', 'ramp', 'gate', 'docking', 'mars', 'ê³„ë¥˜ì¥', 'ê²Œì´íŠ¸', 'ì ‘í˜„', 'ë„í‚¹', 'lead-in line', 'vdgs'],
        'q_codes': ['Q) APRON', 'Q) RAMP'],
        'icon': 'ğŸ…¿ï¸',
        'color': '#6f42c1',  # ë³´ë¼ìƒ‰
        'bg_color': '#e2d9f3'
    },
    'LIGHT': {
        'keywords': ['light', 'lighting', 'lgt', 'ì¡°ëª…', 'ë“±í™”', 'beacon', 'approach light', 'runway light'],
        'q_codes': ['Q) LGT', 'Q) LIGHT'],
        'icon': 'ğŸ’¡',
        'color': '#ffc107',  # ë…¸ë€ìƒ‰
        'bg_color': '#fff3cd'
    },
    'APPROACH': {
        'keywords': ['approach', 'app', 'ì ‘ê·¼', 'ils', 'vor', 'ndb', 'gps approach', 'precision approach'],
        'q_codes': ['Q) APP', 'Q) ILS', 'Q) VOR', 'Q) NDB'],
        'icon': 'ğŸ“¡',
        'color': '#20c997',  # ì²­ë¡ìƒ‰
        'bg_color': '#d1ecf1'
    },
    'DEPARTURE': {
        'keywords': ['departure procedure', 'dep procedure', 'sid', 'standard instrument departure', 'ì¶œë°œ ì ˆì°¨', 'ì´ë¥™ ì ˆì°¨'],
        'q_codes': ['Q) DEP', 'Q) SID'],
        'icon': 'âœˆï¸',
        'color': '#0dcaf0',  # í•˜ëŠ˜ìƒ‰
        'bg_color': '#cff4fc'
    },
    'GPS': {
        'keywords': ['gps', 'gnss', 'raim', 'gps approach', 'gps outage', 'gps unavailable'],
        'q_codes': ['Q) GPS', 'Q) GNSS', 'Q) RAIM'],
        'icon': 'ğŸ›°ï¸',
        'color': '#198754',  # ë…¹ìƒ‰
        'bg_color': '#d1e7dd'
    },
    'OBSTRUCTION': {
        'keywords': ['obstacle', 'obstruction', 'obstacles', 'obstructions', 'ì¥ì• ë¬¼', 'ì¥ì• ë¬¼ êµ¬ì—­'],
        'q_codes': ['Q) OBST', 'Q) OBSTRUCTION'],
        'icon': 'âš ï¸',
        'color': '#dc3545',  # ë¹¨ê°„ìƒ‰ (ìœ„í—˜)
        'bg_color': '#f8d7da'
    },
    'NAVAID': {
        'keywords': ['navaid', 'navigation aid', 'vor', 'ndb', 'ils', 'dme', 'tacan', 'í•­í–‰ë³´ì¡°ì‹œì„¤'],
        'q_codes': ['Q) NAVAID', 'Q) VOR', 'Q) NDB', 'Q) ILS', 'Q) DME'],
        'icon': 'ğŸ“¶',
        'color': '#6c757d',  # íšŒìƒ‰
        'bg_color': '#e9ecef'
    },
    'COMMUNICATION': {
        'keywords': ['communication', 'comm', 'radio', 'frequency', 'í†µì‹ ', 'ì£¼íŒŒìˆ˜', 'frequency change'],
        'q_codes': ['Q) COMM', 'Q) FREQ'],
        'icon': 'ğŸ“»',
        'color': '#0d6efd',  # íŒŒë€ìƒ‰
        'bg_color': '#cfe2ff'
    },
    'AIRWAY': {
        'keywords': ['airway', 'route', 'air route', 'í•­ë¡œ', 'í•­ê³µë¡œ', 'enroute'],
        'q_codes': ['Q) AWY', 'Q) AIRWAY'],
        'icon': 'ğŸ—ºï¸',
        'color': '#fd7e14',  # ì£¼í™©ìƒ‰
        'bg_color': '#fff3cd'
    },
    'AIRSPACE': {
        'keywords': ['airspace', 'air space', 'controlled airspace', 'airspace restriction', 'ê³µì—­', 'ì œí•œê³µì—­'],
        'q_codes': ['Q) AIRSPACE'],
        'icon': 'ğŸŒ',
        'color': '#6f42c1',  # ë³´ë¼ìƒ‰
        'bg_color': '#e2d9f3'
    },
    'AIP': {
        'keywords': ['aip', 'aeronautical information publication', 'í•­ê³µì •ë³´ê°„í–‰ë¬¼'],
        'q_codes': ['Q) AIP'],
        'icon': 'ğŸ“‹',
        'color': '#6c757d',  # íšŒìƒ‰
        'bg_color': '#e9ecef'
    }
}

def analyze_notam_category(notam_text, q_code=None):
    """NOTAM í…ìŠ¤íŠ¸ì™€ Q-codeë¥¼ ë¶„ì„í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
    if not notam_text:
        return 'OTHER'
    
    # í…ìŠ¤íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ë¶„ì„
    text_lower = notam_text.lower()
    
    # Q-codeê°€ ìˆìœ¼ë©´ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©
    if q_code:
        q_code_upper = q_code.upper()
        for category, data in NOTAM_CATEGORIES.items():
            for q_pattern in data['q_codes']:
                if q_pattern.upper() in q_code_upper:
                    return category
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ (ê°€ì¤‘ì¹˜ ì ìš©)
    category_scores = {}
    for category, data in NOTAM_CATEGORIES.items():
        score = 0
        for keyword in data['keywords']:
            keyword_lower = keyword.lower()
            # ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ (ë‹¨ì–´ ê²½ê³„ ê³ ë ¤)
            if re.search(r'\b' + re.escape(keyword_lower) + r'\b', text_lower):
                # ì¤‘ìš”í•œ í‚¤ì›Œë“œëŠ” ë” ë†’ì€ ê°€ì¤‘ì¹˜
                if keyword_lower in ['gate', 'docking', 'mars', 'apron', 'ramp', 'vdgs']:
                    score += 3
                elif keyword_lower in ['runway', 'taxiway', 'approach', 'departure']:
                    score += 2
                else:
                    score += 1
        category_scores[category] = score
    
    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
    if category_scores:
        best_category = max(category_scores.items(), key=lambda x: x[1])[0]
        if category_scores[best_category] > 0:
            return best_category
    
    return 'OTHER'

# ìƒ‰ìƒ íŒ¨í„´ ì •ì˜
RED_STYLE_TERMS = [
    'closed', 'close', 'closing','obstacle','obstacles','obstacle area','obstruction','obstructions',
    'restricted','prohibited','severe','severe weather','volcanic ash','volcanic ash cloud',
    'out of service', 'unserviceable', 'not available','not authorized',
    'caution','cautious','cautionary',
    'hazard','hazardous','hazardous weather','hazardous materials',
    'emergency','emergency landing','emergency landing procedure',
    'ì¥ì• ë¬¼', 'ì¥ì• ë¬¼ êµ¬ì—­', 'ì¥ì• ë¬¼ ì„¤ì¹˜', 'ì¥ì• ë¬¼ ì„¤ì¹˜ë¨',
    'ì‚¬ìš© ë¶ˆê°€', 'ìš´ìš© ì¤‘ë‹¨', 'ì œí•œë¨', 'íì‡„ë¨',
    'ì œí•œ', 'íì‡„', 'ì¤‘ë‹¨', 'ë¶ˆê°€ëŠ¥', 'ë¶ˆê°€',
    'ê¸´ê¸‰', 'ê¸´ê¸‰ ì°©ë¥™', 'ê¸´ê¸‰ ì°©ë¥™ ì ˆì°¨',
    'ê²½ë³´', 'ê²½ë³´ ë°œìƒ', 'ê²½ë³´ í•´ì œ', 'ì˜¤ê²½ë³´',
    'ì£¼ì˜', 'ì£¼ì˜ ìš”êµ¬', 'ì£¼ì˜ ìš”êµ¬ ì‚¬í•­',
    'í¬ë ˆì¸', 'crane', 'cranes',
    'GPS RAIM',  # GPS RAIMì„ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œ ì²˜ë¦¬
    'Non-Precision Approach', 'non-precision approach',
    'í¬ì¥ ê³µì‚¬', 'pavement construction',
]

BLUE_STYLE_PATTERNS = [
    r'\bDVOR\b',  # DVOR
    r'\bAPRON\b',  # APRON
    r'\bANTI-ICING\b',  # ANTI-ICING
    r'\bPAINTING\b',  # PAINTING
    r'\bDE-ICING\b',  # DE-ICING
    r'\bSTAND\s+NUMBER\s+\d+\b',  # STAND NUMBER + ìˆ«ì (ì˜ˆ: STAND NUMBER 711)
    r'\bSTAND\s+\d+\b',  # STAND + ìˆ«ì (ì˜ˆ: STAND 711)
    r'\bSTAND\b',  # STAND
    r'\bILS\b',  # ILS
    r'\bLOC\b',  # LOC
    r'\bS-LOC\b',  # S-LOC
    r'\bMDA\b',  # MDA
    r'\bCAT\b',  # CAT
    r'\bVIS\b',  # VIS
    r'\bRVR\b',  # RVR
    r'\bHAT\b',  # HAT
    r'\bRWY\s+(?:\d{2}[LRC]?(?:/\d{2}[LRC]?)?)\b',  # RWY + ìˆ«ì + ì„ íƒì  L/R/C (ì˜ˆ: RWY 15L/33R)
    r'\bTWY\s+(?:[A-Z]|[A-Z]{2}|[A-Z]\d{1,2})\b',  # TWY + ì•ŒíŒŒë²³(1-2ìë¦¬) ë˜ëŠ” ì•ŒíŒŒë²³+ìˆ«ì(1-2ìë¦¬)
    r'\bTWY\s+[A-Z]\b',  # TWY + í•œ ìë¦¬ ì•ŒíŒŒë²³ (ì˜ˆ: TWY D)
    r'\bTWY\s+[A-Z]{2}\b',  # TWY + ë‘ ìë¦¬ ì•ŒíŒŒë²³ (ì˜ˆ: TWY DD)
    r'\bTWY\s+[A-Z]\d{1,2}\b',  # TWY + ì•ŒíŒŒë²³+ìˆ«ì(1-2ìë¦¬) (ì˜ˆ: TWY D1, TWY D12)
    r'\bVOR\b',  # VOR
    r'\bDME\b',  # DME
    r'\bTWR\b',  # TWR
    r'\bATIS\b',  # ATIS
    r'\bAPPROACH MINIMA\b',  # APPROACH MINIMA
    r'\bVDP\b',  # VDP
    r'\bEST\b',  # EST
    r'\bEastern Standard Time\b',  # Eastern Standard Time
    r'\bIAP\b',  # IAP
    r'\bRNAV\b',  # RNAV
    r'\bGPS\s+(?:APPROACH|APP|APPROACHES)\b',  # GPS APPROACH, GPS APP ë“±
    r'\bLPV\b',  # LPV
    r'\bDA\b',  # DA
    r'\bì£¼ê¸°ì¥\b',  # ì£¼ê¸°ì¥
    r'\bì£¼ê¸°ì¥\s+\d+\b',  # ì£¼ê¸°ì¥ + ìˆ«ì
    r'\bí™œì£¼ë¡œ\s+\d+[A-Z]?\b',  # í™œì£¼ë¡œ + ìˆ«ì + ì„ íƒì  ì•ŒíŒŒë²³
    r'\bP\d+\b',  # P + ìˆ«ì
    r'\bSTANDS?\s*(?:NR\.)?\s*(\d+)\b',  # STANDS NR. 711 í˜•ì‹
    r'\bSTANDS?\s*(\d+)\b',  # STANDS 711 í˜•ì‹
]

def apply_color_styles(text):
    """í…ìŠ¤íŠ¸ì— ìƒ‰ìƒ ìŠ¤íƒ€ì¼ì„ ì ìš©í•©ë‹ˆë‹¤."""
    
    # HTML íƒœê·¸ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì œê±°
    text = re.sub(r'<span[^>]*>', '', text)
    text = re.sub(r'</span>', '', text)
    
    # Runwayë¥¼ RWYë¡œ ë³€í™˜
    text = re.sub(r'\bRunway\s+', 'RWY ', text, flags=re.IGNORECASE)
    text = re.sub(r'\brunway\s+', 'RWY ', text, flags=re.IGNORECASE)
    
    # GPS RAIMì„ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œ ì²˜ë¦¬
    text = re.sub(
        r'\bGPS\s+RAIM\b',
        r'<span style="color: red; font-weight: bold;">GPS RAIM</span>',
        text
    )
    
    # ë¹¨ê°„ìƒ‰ ìŠ¤íƒ€ì¼ ì ìš© (GPS RAIM ì œì™¸)
    for term in [t for t in RED_STYLE_TERMS if t != 'GPS RAIM']:
        if term.lower() in text.lower():
            text = re.sub(
                re.escape(term),
                lambda m: f'<span style="color: red; font-weight: bold;">{m.group()}</span>',
                text,
                flags=re.IGNORECASE
            )
    
    # í™œì£¼ë¡œ ë° ìœ ë„ë¡œ íŒ¨í„´ ì²˜ë¦¬
    rwy_twy_patterns = [
        (r'\b(RWY\s*\d{2}[LRC]?(?:/\d{2}[LRC]?)?)\b', 'blue'),  # RWY 15L/33R
        (r'\b(RWY\s*\|)\b', 'blue'),  # RWY |
        (r'\b(RWY)\b', 'blue'),  # RWY ë‹¨ë…
        (r'\b(TWY\s*[A-Z](?:\s+AND\s+[A-Z])*)\b', 'blue'),  # TWY D, TWY D AND E
        (r'\b(TWY\s*[A-Z]\d+)\b', 'blue'),  # TWY D1
    ]
    
    for pattern, color in rwy_twy_patterns:
        text = re.sub(
            pattern,
            lambda m: f' <span style="color: {color}; font-weight: bold;">{m.group(1).strip()}</span>',
            text
        )
    
    # íŒŒë€ìƒ‰ ìŠ¤íƒ€ì¼ ì ìš© (RWY, TWY ì œì™¸)
    for pattern in [p for p in BLUE_STYLE_PATTERNS if not (p.startswith(r'\bRWY') or p.startswith(r'\bTWY'))]:
        text = re.sub(
            pattern,
            lambda m: f'<span style="color: blue; font-weight: bold;">{m.group(0)}</span>',
            text,
            flags=re.IGNORECASE
        )
    
    # HTML íƒœê·¸ ì¤‘ë³µ ë°©ì§€
    text = re.sub(r'(<span[^>]*>)+', r'\1', text)
    text = re.sub(r'(</span>)+', r'\1', text)
    text = re.sub(r'\s+', ' ', text)  # ì¤‘ë³µ ê³µë°± ì œê±°
    
    return text.strip()

def translate_notam(text):
    """NOTAM í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ì™€ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤."""
    try:
        # NOTAM ë²ˆí˜¸ ì¶”ì¶œ
        notam_number = text.split()[0]
        # NOTAM íƒ€ì… ì‹ë³„
        notam_type = identify_notam_type(notam_number)
        # ì˜ì–´ ë²ˆì—­
        english_translation = perform_translation(text, "en", notam_type)
        english_translation = apply_color_styles(english_translation)
        # í•œêµ­ì–´ ë²ˆì—­
        korean_translation = perform_translation(text, "ko", notam_type)
        korean_translation = apply_color_styles(korean_translation)
        return {
            'english_translation': english_translation,
            'korean_translation': korean_translation,
            'error_message': None
        }
    except Exception as e:
        print(f"ë²ˆì—­ ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        import traceback
        traceback.print_exc()
        return {
            'english_translation': 'Translation failed',
            'korean_translation': 'ë²ˆì—­ ì‹¤íŒ¨',
            'error_message': str(e)
        }

def extract_e_section(notam_text):
    """
    NOTAM í…ìŠ¤íŠ¸ì—ì„œ E ì„¹ì…˜ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    # E ì„¹ì…˜ íŒ¨í„´ ë§¤ì¹­
    e_section_pattern = r'E\)\s*(.*?)(?=\s*[A-Z]\)|$)'
    match = re.search(e_section_pattern, notam_text, re.DOTALL)
    
    if match:
        e_section = match.group(1).strip()
        # CREATED: ì´í›„ì˜ í…ìŠ¤íŠ¸ ì œê±°
        e_section = re.sub(r'CREATED:.*$', '', e_section, flags=re.DOTALL).strip()
        return e_section
    return ""  # E ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•˜ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜

def preprocess_notam_text(notam_text):
    """
    NOTAM í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­ ì „ì— ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    # AIRAC AIP SUPê³¼ UTCë¥¼ ì„ì‹œ í† í°ìœ¼ë¡œ ëŒ€ì²´
    notam_text = re.sub(r'\bAIRAC AIP SUP\b', 'AIRAC_AIP_SUP', notam_text)
    notam_text = re.sub(r'\bUTC\b', 'UTC_TOKEN', notam_text)
    
    # ë‹¤ë¥¸ NO_TRANSLATE_TERMS ì²˜ë¦¬
    for term in NO_TRANSLATE_TERMS:
        if term not in ["AIRAC AIP SUP", "UTC"]:  # ì´ë¯¸ ì²˜ë¦¬í•œ í•­ëª© ì œì™¸
            notam_text = re.sub(r'\b' + re.escape(term) + r'\b', term.replace(' ', '_'), notam_text)
    
    return notam_text

def postprocess_translation(translated_text):
    """
    ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë¥¼ í›„ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    # ì„ì‹œ í† í°ì„ ì›ë˜ í˜•íƒœë¡œ ë³µì›
    translated_text = translated_text.replace("AIRAC_AIP_SUP", "AIRAC AIP SUP")
    translated_text = translated_text.replace("UTC_TOKEN", "UTC")
    
    # ë‹¤ë¥¸ NO_TRANSLATE_TERMS ë³µì›
    for term in NO_TRANSLATE_TERMS:
        if term not in ["AIRAC AIP SUP", "UTC"]:  # ì´ë¯¸ ì²˜ë¦¬í•œ í•­ëª© ì œì™¸
            translated_text = translated_text.replace(term.replace(' ', '_'), term)
    
    # ë¶ˆí•„ìš”í•œ ë²ˆì—­ ë‚´ìš© ì œê±°
    unwanted_translation_patterns = [
        r'ê³µê°„\s*-->\s*\*\*ë²ˆì—­:\*\*.*?ì´ê±´ í•„ìš”ì—†ëŠ” ë§ì´ì•¼\.\.\.',
        r'ê³µê°„\s*-->\s*\*\*ë²ˆì—­:\*\*.*?ì´ê±´ í•„ìš”ì—†ëŠ” ë§ì´ì•¼',
        r'ê³µê°„\s*-->\s*.*?ì´ê±´ í•„ìš”ì—†ëŠ” ë§ì´ì•¼\.\.\.',
        r'ê³µê°„\s*-->\s*.*?ì´ê±´ í•„ìš”ì—†ëŠ” ë§ì´ì•¼',
        r'\*\*ë²ˆì—­:\*\*.*?ì´ê±´ í•„ìš”ì—†ëŠ” ë§ì´ì•¼\.\.\.',
        r'\*\*ë²ˆì—­:\*\*.*?ì´ê±´ í•„ìš”ì—†ëŠ” ë§ì´ì•¼',
        r'ì´ê±´ í•„ìš”ì—†ëŠ” ë§ì´ì•¼\.\.\.',
        r'ì´ê±´ í•„ìš”ì—†ëŠ” ë§ì´ì•¼',
        # ê¸°íƒ€ ë¶ˆí•„ìš”í•œ íŒ¨í„´ë“¤ - ë” ì •í™•í•œ íŒ¨í„´
        r'ë²ˆì—­:\s*[^ê°€-í£]*$',  # "ë²ˆì—­:" ë’¤ì— í•œê¸€ì´ ì•„ë‹Œ ë‚´ìš©
        r'ë²ˆì—­\s*:\s*[^ê°€-í£]*$',
        r'^\s*ë²ˆì—­\s*$',
        r'^\s*ë²ˆì—­:\s*$',
        r'^\s*\*\*ë²ˆì—­:\*\*\s*$',
        r'^\s*ê³µê°„\s*-->\s*$',
        r'^\s*ê³µê°„\s*$',
        # "ë²ˆì—­:" ë’¤ì— íŠ¹ì • íŒ¨í„´ë“¤
        r'ë²ˆì—­:\s*ì´ê²ƒì€.*?ì…ë‹ˆë‹¤\.',
        r'ë²ˆì—­:\s*í…ŒìŠ¤íŠ¸.*?ì…ë‹ˆë‹¤\.',
        r'ë²ˆì—­:\s*[ê°€-í£]*\s*í…ŒìŠ¤íŠ¸',
    ]
    
    import re
    for pattern in unwanted_translation_patterns:
        translated_text = re.sub(pattern, '', translated_text, flags=re.MULTILINE | re.DOTALL)
    
    # ë¹ˆ ì¤„ ì •ë¦¬
    lines = translated_text.split('\n')
    cleaned_lines = []
    for line in lines:
        line = line.strip()
        # "ë²ˆì—­ ì‹¤íŒ¨"ëŠ” ìœ ì§€í•˜ê³ , ë‹¤ë¥¸ ë¶ˆí•„ìš”í•œ "ë²ˆì—­:" ì‹œì‘ ë¼ì¸ë§Œ ì œê±°
        if line and not (line.startswith('ë²ˆì—­:') and not line.startswith('ë²ˆì—­ ì‹¤íŒ¨')):
            cleaned_lines.append(line)
    
    return '\n'.join(cleaned_lines).strip()

def perform_translation(text, target_lang, notam_type):
    """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ NOTAM ë²ˆì—­ ìˆ˜í–‰"""
    try:
        # E ì„¹ì…˜ë§Œ ì¶”ì¶œ
        e_section = extract_e_section(text)
        if not e_section:
            return "ë²ˆì—­í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

        # ë²ˆì—­ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        if target_lang == "en":
            prompt = f"""Translate the following NOTAM E section to English. Follow these rules strictly:

1. Keep these terms exactly as they are:
   - NOTAM, AIRAC, AIP, SUP, AMDT, WEF, TIL, UTC
   - GPS, RAIM, NPA, PBN, RNAV, RNP
   - RWY, TWY, APRON, TAXI, SID, STAR, IAP
   - SFC, AMSL, AGL, MSL
   - PSN, RADIUS, HGT, HEIGHT
   - TEMP, PERM, OBST, FIREWORKS
   - All coordinates, frequencies, and measurements
   - All dates and times in original format
   - All aircraft stand numbers and references

2. For specific terms:
   - Translate "CLOSED" as "CLOSED"
   - Translate "PAVEMENT CONSTRUCTION" as "PAVEMENT CONSTRUCTION"
   - Translate "OUTAGES" as "OUTAGES"
   - Translate "PREDICTED FOR" as "PREDICTED FOR"
   - Translate "WILL TAKE PLACE" as "WILL TAKE PLACE"
   - Keep "ACFT" as "ACFT"
   - Keep "NR." as "NR."
   - Keep all parentheses and their contents intact
   - Always close parentheses if they are opened

3. Maintain the exact format of:
   - Multiple items (e.g., "1.PSN: ..., 2.PSN: ...")
   - Coordinates and measurements
   - Dates and times
   - NOTAM sections
   - Aircraft stand numbers and references
   - Complete all unfinished sentences or phrases

4. Do not include:
   - NOTAM number
   - Dates or times from outside the E section
   - Airport codes
   - "E:" prefix
   - Any additional text or explanations
   - "CREATED:" and following text

Original text:
{e_section}

Translated text:"""
        else:  # Korean
            prompt = f"""ë‹¤ìŒ NOTAM E ì„¹ì…˜ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. ë‹¤ìŒ ê·œì¹™ì„ ì—„ê²©íˆ ë”°ë¥´ì„¸ìš”:

1. ë‹¤ìŒ ìš©ì–´ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€:
   - NOTAM, AIRAC, AIP, SUP, AMDT, WEF, TIL, UTC
   - GPS, RAIM, PBN, RNAV, RNP
   - RWY, TWY, APRON, TAXI, SID, STAR, IAP
   - SFC, AMSL, AGL, MSL
   - PSN, RADIUS, HGT, HEIGHT
   - TEMP, PERM, OBST, FIREWORKS
   - ëª¨ë“  ì¢Œí‘œ, ì£¼íŒŒìˆ˜, ì¸¡ì •ê°’
   - ëª¨ë“  ë‚ ì§œì™€ ì‹œê°„ì€ ì›ë˜ í˜•ì‹ ìœ ì§€
   - ëª¨ë“  í•­ê³µê¸° ì£¼ê¸°ì¥ ë²ˆí˜¸ì™€ ì°¸ì¡°

2. íŠ¹ì • ìš©ì–´ ë²ˆì—­:
   - "CLOSED"ëŠ” "íì‡„"ë¡œ ë²ˆì—­
   - "PAVEMENT CONSTRUCTION"ì€ "í¬ì¥ ê³µì‚¬"ë¡œ ë²ˆì—­
   - "OUTAGES"ëŠ” "ê¸°ëŠ¥ ìƒì‹¤"ë¡œ ë²ˆì—­
   - "PREDICTED FOR"ëŠ” "ì— ì˜í–¥ì„ ì¤„ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë¨"ìœ¼ë¡œ ë²ˆì—­
   - "WILL TAKE PLACE"ëŠ” "ì§„í–‰ë  ì˜ˆì •"ìœ¼ë¡œ ë²ˆì—­
   - "NPA"ëŠ” "ë¹„ì •ë°€ì ‘ê·¼"ìœ¼ë¡œ ë²ˆì—­

3. ì¤‘ìš”í•œ ê·œì¹™:
   - ë²ˆì—­ ê²°ê³¼ì— "ë²ˆì—­:", "ê³µê°„", "ì´ê±´ í•„ìš”ì—†ëŠ” ë§ì´ì•¼" ë“±ì˜ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
   - ìˆœìˆ˜í•˜ê²Œ NOTAM ë‚´ìš©ë§Œ ë²ˆì—­í•˜ì„¸ìš”
   - ë²ˆì—­ ê³¼ì •ì´ë‚˜ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
   - "FLW"ëŠ” "ë‹¤ìŒê³¼ ê°™ì´"ë¡œ ë²ˆì—­
   - "ACFT"ëŠ” "í•­ê³µê¸°"ë¡œ ë²ˆì—­
   - "NR."ëŠ” "ë²ˆí˜¸"ë¡œ ë²ˆì—­
   - "ESTABLISHMENT OF"ëŠ” "ì‹ ì„¤"ë¡œ ë²ˆì—­
   - "INFORMATION OF"ëŠ” "ì •ë³´"ë¡œ ë²ˆì—­
   - "CIRCLE"ì€ "ì›í˜•"ìœ¼ë¡œ ë²ˆì—­
   - "CENTERED"ëŠ” "ì¤‘ì‹¬"ìœ¼ë¡œ ë²ˆì—­
   - "DUE TO"ëŠ” "ë¡œ ì¸í•´"ë¡œ ë²ˆì—­
   - "MAINT"ëŠ” "ì •ë¹„"ë¡œ ë²ˆì—­
   - "NML OPS"ëŠ” "ì •ìƒ ìš´ì˜"ìœ¼ë¡œ ë²ˆì—­
   - ê´„í˜¸ ì•ˆì˜ ë‚´ìš©ì€ ê°€ëŠ¥í•œ í•œ ë²ˆì—­
   - ì—´ë¦° ê´„í˜¸ëŠ” ë°˜ë“œì‹œ ë‹«ê¸°

3. ë‹¤ìŒ í˜•ì‹ ì •í™•íˆ ìœ ì§€:
   - ì—¬ëŸ¬ í•­ëª© (ì˜ˆ: "1.PSN: ..., 2.PSN: ...")
   - ì¢Œí‘œì™€ ì¸¡ì •ê°’
   - ë‚ ì§œì™€ ì‹œê°„
   - NOTAM ì„¹ì…˜
   - í•­ê³µê¸° ì£¼ê¸°ì¥ ë²ˆí˜¸ì™€ ì°¸ì¡°
   - ë¬¸ì¥ì´ë‚˜ êµ¬ì ˆì´ ì™„ì„±ë˜ì§€ ì•Šì€ ê²½ìš° ì™„ì„±

4. ë‹¤ìŒ ë‚´ìš© í¬í•¨í•˜ì§€ ì•ŠìŒ:
   - NOTAM ë²ˆí˜¸
   - E ì„¹ì…˜ ì™¸ë¶€ì˜ ë‚ ì§œë‚˜ ì‹œê°„
   - ê³µí•­ ì½”ë“œ
   - "E:" ì ‘ë‘ì‚¬
   - ì¶”ê°€ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸
   - "CREATED:" ì´í›„ì˜ í…ìŠ¤íŠ¸

5. ë²ˆì—­ ìŠ¤íƒ€ì¼:
   - ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì–´ìˆœ ì‚¬ìš©
   - ë¶ˆí•„ìš”í•œ ì¡°ì‚¬ë‚˜ ì–´ë¯¸ ì œê±°
   - ê°„ê²°í•˜ê³  ëª…í™•í•œ í‘œí˜„ ì‚¬ìš©
   - ì¤‘ë³µëœ í‘œí˜„ ì œê±°
   - ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ì—†ë„ë¡ ì£¼ì˜
   - "DUE TO"ëŠ” í•­ìƒ "ë¡œ ì¸í•´"ë¡œ ë²ˆì—­í•˜ê³  "TO"ë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
   - "CEILING"ì€ ë°˜ë“œì‹œ "ìš´ê³ "ë¡œ ë²ˆì—­

ì›ë¬¸:
{e_section}

ë²ˆì—­ë¬¸:"""
        
        # Gemini API í˜¸ì¶œ
        if model and GEMINI_AVAILABLE:
            response = model.generate_content(prompt)
            translated_text = response.text.strip()
        else:
            translated_text = "GEMINI APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # "CREATED:" ì´í›„ì˜ í…ìŠ¤íŠ¸ ì œê±°
        translated_text = re.sub(r'\s*CREATED:.*$', '', translated_text)
        
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        translated_text = re.sub(r'\s+', ' ', translated_text)
        
        # ê´„í˜¸ ë‹«ê¸° í™•ì¸
        if translated_text.count('(') > translated_text.count(')'):
            translated_text += ')'
        
        # ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì •
        translated_text = re.sub(r'í\s+ì‡„', 'íì‡„', translated_text)
        
        return translated_text
    except Exception as e:
        print(f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        import traceback
        traceback.print_exc()
        return "ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def identify_notam_type(notam_number):
    """NOTAM ë²ˆí˜¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ NOTAM íƒ€ì…ì„ ì‹ë³„í•©ë‹ˆë‹¤."""
    prefix = notam_number[0].upper()
    
    notam_types = {
        'A': "AERODROME NOTAM",
        'B': "BEACON NOTAM",
        'C': "COMMUNICATION NOTAM",
        'D': "DANGER AREA NOTAM",
        'E': "ENROUTE NOTAM",
        'F': "FLIGHT INFORMATION NOTAM",
        'G': "GENERAL NOTAM",
        'H': "HELIPORT NOTAM",
        'I': "INSTRUMENT APPROACH NOTAM",
        'L': "LIGHTING NOTAM",
        'M': "MILITARY NOTAM",
        'N': "NEW NOTAM",
        'O': "OBSTACLE NOTAM",
        'P': "PROHIBITED AREA NOTAM",
        'R': "RESTRICTED AREA NOTAM",
        'S': "SNOWTAM",
        'T': "TERMINAL NOTAM",
        'U': "UNMANNED AIRCRAFT NOTAM",
        'V': "VOLCANIC ACTIVITY NOTAM",
        'W': "WARNING NOTAM",
        'X': "OTHER NOTAM",
        'Z': "TRIGGER NOTAM"
    }
    
    return notam_types.get(prefix, "GENERAL NOTAM")

__all__ = ['apply_color_styles', 'RED_STYLE_TERMS', 'BLUE_STYLE_PATTERNS', 'NOTAMFilter']


class NOTAMFilter:
    """NOTAM í•„í„°ë§ ë° íŒŒì‹± í´ë˜ìŠ¤"""
    
    def __init__(self):
        """NOTAMFilter ì´ˆê¸°í™”"""
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger(__name__)
        
        # íŒ¨í‚¤ì§€ë³„ ê³µí•­ ìˆœì„œ ì •ì˜
        self.package_airport_order = {
            'package1': ['RKSI', 'VVDN', 'VVTS', 'VVCR', 'SECY'],
            'package2': ['RKSI', 'RKPC', 'ROAH', 'RJFF', 'RORS', 'RCTP', 'VHHH', 'ZJSY', 'VVNB', 'VVDN', 'VVTS'],
            'package3': ['RKRR', 'RJJJ', 'RCAA', 'VHHK', 'ZJSA', 'VVHN', 'VVHM']
        }
        
        # ë¡œê±° í•¸ë“¤ëŸ¬ ì„¤ì •
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
            
        # ê³µí•­ ë°ì´í„° ë¡œë“œ
        self.airports_data = self._load_airports_data()
        
        # ì‹œê°„ëŒ€ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”)
        self.timezone_cache = {}
        
    def _detect_package_type(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í‚¤ì§€ íƒ€ì…ì„ ê°ì§€"""
        if 'KOREAN AIR NOTAM PACKAGE 1' in text:
            return 'package1'
        elif 'KOREAN AIR NOTAM PACKAGE 2' in text:
            return 'package2'
        elif 'KOREAN AIR NOTAM PACKAGE 3' in text:
            return 'package3'
        return None
        
    def _get_airport_priority(self, airport_code, package_type):
        """ê³µí•­ ì½”ë“œì˜ ìš°ì„ ìˆœìœ„ë¥¼ ë°˜í™˜"""
        if package_type and package_type in self.package_airport_order:
            order_list = self.package_airport_order[package_type]
            try:
                return order_list.index(airport_code)
            except ValueError:
                return 999  # ìˆœì„œì— ì—†ëŠ” ê³µí•­ì€ ë§ˆì§€ë§‰ì—
        return 999
        
    def _load_airports_data(self):
        """ê³µí•­ ë°ì´í„° ë¡œë“œ"""
        airports_data = {}
        try:
            # src í´ë”ì˜ ê³µí•­ ë°ì´í„° ì‚¬ìš©
            csv_path = os.path.join(os.path.dirname(__file__), 'airports_timezones.csv')
            
            if os.path.exists(csv_path):
                with open(csv_path, 'r', encoding='utf-8-sig') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        icao_code = row.get('ident')  # CSV íŒŒì¼ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª…
                        if icao_code:
                            time_zone = row.get('time_zone', 'UTC')
                            # UTC+8 -> +08:00 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                            if time_zone.startswith('UTC+'):
                                utc_offset = '+' + time_zone[4:].zfill(2) + ':00'
                            elif time_zone.startswith('UTC-'):
                                utc_offset = '-' + time_zone[4:].zfill(2) + ':00'
                            else:
                                utc_offset = '+00:00'
                                
                            airports_data[icao_code] = {
                                'name': row.get('code', ''),
                                'country': '',
                                'timezone': time_zone,
                                'utc_offset': utc_offset
                            }
            else:
                print(f"Airport data file not found: {csv_path}")
                
        except Exception as e:
            print(f"Error loading airport data: {e}")
            
        return airports_data
    
    def get_timezone(self, airport_code):
        """ê³µí•­ ì½”ë“œì— ë”°ë¥¸ íƒ€ì„ì¡´ ì •ë³´ ë°˜í™˜ (ìºì‹± ì ìš©)"""
        # ìºì‹œ í™•ì¸
        if airport_code in self.timezone_cache:
            return self.timezone_cache[airport_code]
        
        timezone_result = self._calculate_timezone(airport_code)
        
        # ìºì‹œì— ì €ì¥
        self.timezone_cache[airport_code] = timezone_result
        
        return timezone_result
    
    def _calculate_timezone(self, airport_code):
        """ì‹¤ì œ ì‹œê°„ëŒ€ ê³„ì‚° (ìºì‹± ì—†ì´)"""
        # 1ë‹¨ê³„: CSV ë°ì´í„°ì—ì„œ ì •í™•í•œ ì‹œê°„ëŒ€ ì¡°íšŒ
        if airport_code in self.airports_data:
            csv_timezone = self.airports_data[airport_code].get('utc_offset', '+00:00')
            # DST ì ìš© ì—¬ë¶€ í™•ì¸
            return self._apply_dst_if_needed(airport_code, csv_timezone)
        
        # 2ë‹¨ê³„: ê³ ê¸‰ ì‹œê°„ëŒ€ ì‹œìŠ¤í…œ ì‚¬ìš© ì‹œë„ (API ë¹„í™œì„±í™”ë¡œ ì„±ëŠ¥ í–¥ìƒ)
        try:
            from src.icao import get_utc_offset
            advanced_timezone = get_utc_offset(airport_code, use_api=False)  # API ë¹„í™œì„±í™”
            if advanced_timezone and advanced_timezone != "UTC+0":
                # UTC+9 -> +09:00 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                if advanced_timezone.startswith('UTC+'):
                    return '+' + advanced_timezone[4:] + ':00'
                elif advanced_timezone.startswith('UTC-'):
                    return '-' + advanced_timezone[4:] + ':00'
        except Exception as e:
            print(f"Advanced timezone system failed: {e}")
        
        # 3ë‹¨ê³„: ê¸°ë³¸ íƒ€ì„ì¡´ ì„¤ì • (ICAO ì½”ë“œ ì²« ê¸€ì ê¸°ì¤€)
        if airport_code.startswith('RK'):  # í•œêµ­
            return '+09:00'
        elif airport_code.startswith('RJ'):  # ì¼ë³¸
            return '+09:00'
        elif airport_code.startswith('ZB') or airport_code.startswith('ZG'):  # ì¤‘êµ­
            return '+08:00'
        elif airport_code.startswith('VV'):  # ë² íŠ¸ë‚¨
            return '+07:00'
        elif airport_code.startswith('K'):  # ë¯¸êµ­ ê³µí•­ë“¤
            # ë¯¸êµ­ ì‹œê°„ëŒ€ë³„ ê¸°ë³¸ ì„¤ì • (DST ê³ ë ¤í•˜ì§€ ì•Šê³  í‘œì¤€ ì‹œê°„ ì‚¬ìš©)
            if airport_code.startswith('KS'):  # ì„œë¶€ (ì‹œì• í‹€, ìƒŒí”„ë€ì‹œìŠ¤ì½”)
                return '-08:00'  # PST
            elif airport_code.startswith('KL'):  # ì„œë¶€ (ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤)
                return '-08:00'  # PST
            elif airport_code.startswith('KD'):  # ì¤‘ë¶€ (ë´ë²„)
                return '-07:00'  # MST
            elif airport_code.startswith('KM'):  # ì¤‘ë¶€ (ì‹œì¹´ê³ )
                return '-06:00'  # CST
            elif airport_code.startswith('KE'):  # ë™ë¶€ (ë‰´ìš•)
                return '-05:00'  # EST
            else:
                return '-06:00'  # ê¸°ë³¸ ì¤‘ë¶€ ì‹œê°„ëŒ€
        else:
            return '+00:00'  # UTC
    
    def _apply_dst_if_needed(self, airport_code, timezone_offset):
        """DSTê°€ í•„ìš”í•œ ê³µí•­ì— ëŒ€í•´ ì„œë¨¸íƒ€ì„ ì ìš©"""
        # DSTê°€ ì ìš©ë˜ëŠ” ì§€ì—­ë“¤ (ë¯¸êµ­, ìºë‚˜ë‹¤, ìœ ëŸ½ ë“±)
        dst_regions = ['K', 'C', 'E', 'L']  # ë¯¸êµ­, ìºë‚˜ë‹¤, ìœ ëŸ½
        
        if airport_code[0] in dst_regions:
            try:
                # ê°„ë‹¨í•œ DST íŒë‹¨ (3ì›”~10ì›”)
                from datetime import datetime
                current_month = datetime.now().month
                dst_active = 3 <= current_month <= 10
                
                if dst_active:
                    # CSVì˜ ê°’ì´ ì´ë¯¸ DST ì ìš©ëœ ê°’ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    return timezone_offset
                else:
                    # í‘œì¤€ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ (DST ë¹„í™œì„±í™” ì‹œ)
                    if timezone_offset.startswith('-'):
                        # ìŒìˆ˜ ì‹œê°„ëŒ€ì—ì„œ 1ì‹œê°„ ë¹¼ê¸° (í‘œì¤€ ì‹œê°„ìœ¼ë¡œ)
                        offset_hours = int(timezone_offset[1:3])
                        offset_minutes = int(timezone_offset[4:6])
                        new_hours = offset_hours - 1
                        if new_hours < 0:
                            new_hours = 0
                        return f"-{new_hours:02d}:{offset_minutes:02d}"
                    elif timezone_offset.startswith('+'):
                        # ì–‘ìˆ˜ ì‹œê°„ëŒ€ì—ì„œ 1ì‹œê°„ ë¹¼ê¸° (í‘œì¤€ ì‹œê°„ìœ¼ë¡œ)
                        offset_hours = int(timezone_offset[1:3])
                        offset_minutes = int(timezone_offset[4:6])
                        new_hours = offset_hours - 1
                        if new_hours < 0:
                            new_hours = 0
                        return f"+{new_hours:02d}:{offset_minutes:02d}"
            
            except Exception as e:
                print(f"DST application error: {e}")
        
        return timezone_offset
    
    def _clean_additional_info(self, notam_text):
        """NOTAMì—ì„œ ì¶”ê°€ ì •ë³´ ì œê±°"""
        lines = notam_text.split('\n')
        cleaned_lines = []
        
        # ì¶”ê°€ ì •ë³´ íŒ¨í„´ë“¤
        additional_info_patterns = [
            r'^\d+\.\s*COMPANY\s+RADIO\s*:',
            r'^\d+\.\s*COMPANY\s+ADVISORY\s*:',
            r'^\d+\.\s*RADIO\s*:',
            r'^\d+\.\s*ADVISORY\s*:',
            r'^\d+\.\s*[A-Z\s]+\s*:',
            r'^\[PAX\]',
            r'^\[JINAIR\]',
            r'^CTC\s+TWR',
            r'^NIL\s*$',
            r'^COMMENT\)\s*$',
            # ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ COMPANY ADVISORY í•­ëª©ë“¤ (COAD NOTAMì€ ì œì™¸)
            # r'^\d+\.\s+\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:UFN|PERM)\s+[A-Z]{4}\s+COAD\d+/\d+',  # COAD NOTAMì€ ìœ íš¨í•œ NOTAMì´ë¯€ë¡œ ì œê±°í•˜ì§€ ì•ŠìŒ
            r'^\d+\.\s+\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:UFN|PERM)\s+[A-Z]{4}\s+(?!COAD)[A-Z]+\d+/\d+',
            # OCR ì˜¤ë¥˜ íŒ¨í„´ë“¤ ì¶”ê°€
            r'Ã¢â€”CÂ¼O\s*MPANY',
            r'Ã¢â€”CÂ¼O\s*COMPANY',
            r'Ã¢â€”AÂ¼R\s*RIVAL',
            r'Ã¢â€”OÂ¼B\s*STRUCTION',
            r'Ã¢â€”GÂ¼P\s*S',
            r'Ã¢â€”RÂ¼U\s*NWAY',
            r'Ã¢â€”AÂ¼PP\s*ROACH',
            r'Ã¢â€”TÂ¼A\s*XIWAY',
            r'Ã¢â€”NÂ¼A\s*VAID',
            r'Ã¢â€”DÂ¼E\s*PARTURE',
            r'Ã¢â€”RÂ¼U\s*NWAY\s*LIGHT',
            r'Ã¢â€”AÂ¼IP',
            r'Ã¢â€”OÂ¼T\s*HER',
            # ì¶”ê°€ íŒ¨í„´ë“¤ - ë² íŠ¸ë‚¨ ê´€ë ¨ ë‚´ìš©
            r'//REQUIRED WEATHER MINIMA IN VIETNAM//',
            r'// SPEED LIMIT WHEN USING VDGS //',
            r'CAAV\(CIVIL AVIATION AUTHORITY OF VIETNAM\)',
            r'CARGO FLIGHTS ARE NOT ALLOWED TO LAND EARLIER',
            r'PLZ DEPART TO HAN AFTER ETD ON FPL',
            r'ANY QUESTIONS ABOUT ETD OF FLT',
            r'CONTACT KOREANAIR DISPATCH BY CO-RADIO',
            r'// SIMILAR CALLSIGN //',
            r'KE\d+ AND KE\d+ MAY OPERATE ON SAME FREQ',
            r'PLZ PAY MORE ATTENTION TO ATC COMMUNICATION',
            r'CEILING IS ALWAYS SHOWN IN SMALLER SIZE',
            r'MUST NOT EXCEED \d+KTS FROM STARTING POINT',
            r'REDUCE SPEED TO STOP AT THE DESIGNATED STOP LINE',
            # ê¸°íƒ€ ë¶ˆí•„ìš”í•œ íŒ¨í„´ë“¤
            r'^\d+\.\s+ANY REVISION TO RWY CLOSURE',
            r'^\d+\.\s+IN THE EVENT THAT THE OPERATIONAL RWY',
            r'DEPENDENT ON THE WORK BEING CARRIED OUT',
            r'IT MAY TAKE UP TO \d+ HRS FOR A CLOSED RWY',
        ]
        
        for line in lines:
            line_stripped = line.strip()
            # ì¶”ê°€ ì •ë³´ íŒ¨í„´ì— ë§¤ì¹˜ë˜ë©´ ì œê±°
            if any(re.search(pattern, line_stripped, re.IGNORECASE) for pattern in additional_info_patterns):
                continue
            cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines).strip()
    
    def _parse_notam_section(self, notam_text):
        """NOTAM í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ì •ë³´ ì¶”ì¶œ"""
        # ì¶”ê°€ ì •ë³´ ì œê±°
        cleaned_text = self._clean_additional_info(notam_text)
        
        parsed_notam = {}
        
        # NOTAMì´ ì•„ë‹Œ ë¹„ì •ë³´ ì„¹ì…˜ ì²´í¬ (COMPANY ADVISORY ë“±)
        if any(phrase in cleaned_text.upper() for phrase in ['COMPANY ADVISORY', 'OTHER INFORMATION', 'DEP:', 'DEST:', 'ALTN:', 'SECY']):
            # ê¸¸ì´ê°€ ê¸´ ê²½ìš° ë” ì—„ê²©í•œ ì²´í¬
            if len(cleaned_text) > 400:
                self.logger.debug(f"ê¸´ ë¹„NOTAM ì„¹ì…˜ ê°ì§€í•˜ì—¬ ê±´ë„ˆë›°ê¸°: {cleaned_text[:100]}...")
                return {}
        
        # ê³µí•­ ì •ë³´ ì„¹ì…˜ ì²´í¬ (íŠ¹ë³„í•œ íŒ¨í„´ë“¤)
        airport_info_patterns = [
            r'^\d+\. RUNWAY',  # "1. RUNWAY :"
            r'^\d+\. COMPANY RADIO',  # "2. COMPANY RADIO :"
            r'TAKEOFF PERFORMANCE INFORMATION',
            r'NOTAM A\d{4}/\d{2}.*NO IMPACT',  # ì„±ëŠ¥ ì •ë³´ ê´€ë ¨
            r'CHECK RWY ID FOR TODC REQUEST',
            r'COMPANY MINIMA FOR CAT II/III',  # ì¶”ê°€ íŒ¨í„´
            r'131\.500.*KOREAN AIR INCHEON',  # ì£¼íŒŒìˆ˜ ì •ë³´
            r'129\.35.*ASIANA INCHEON'  # ì¶”ê°€ ì£¼íŒŒìˆ˜ ì •ë³´
        ]
        
        if any(re.search(pattern, cleaned_text, re.IGNORECASE) for pattern in airport_info_patterns):
            if len(cleaned_text) > 500:  # ë§¤ìš° ê¸´ ê³µí•­ ì •ë³´ ì„¹ì…˜
                self.logger.debug(f"ê¸´ ê³µí•­ ì •ë³´ ì„¹ì…˜ ê°ì§€í•˜ì—¬ ê±´ë„ˆë›°ê¸°: {cleaned_text[:100]}...")
                return {}
        
        # ì¶”ê°€ ì²´í¬: ê³µí•­ ì •ë³´ë¡œ ë³´ì´ëŠ” íŠ¹ë³„í•œ íŒ¨í„´ë“¤
        # ë‹¨, NOTAM ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°ì—ëŠ” ì§„ì§œ NOTAMì¼ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë¯€ë¡œ ê´€ëŒ€í•˜ê²Œ ì²˜ë¦¬
        has_notam_number = re.search(r'\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN)\s+[A-Z]{4}\s+[A-Z0-9]+/\d{2}', cleaned_text)
        if cleaned_text.count('RWY') > 3 or cleaned_text.count('CAT') > 2:
            if len(cleaned_text) > 800:  # ë§¤ìš° ê¸´ ê²½ë¡œ ì •ë³´ë‚˜ ì„±ëŠ¥ ì •ë³´
                # NOTAM ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°ì—ëŠ” ê±´ë„ˆë›°ì§€ ì•ŠìŒ
                if not has_notam_number:
                    self.logger.debug(f"ë§¤ìš° ê¸´ ê³µí•­ ì„±ëŠ¥ ì •ë³´ ê°ì§€í•˜ì—¬ ê±´ë„ˆë›°ê¸°: {cleaned_text[:100]}...")
                    return {}
                else:
                    self.logger.debug(f"NOTAM ë²ˆí˜¸ê°€ ìˆìœ¼ë¯€ë¡œ ê¸¸ì´ ì œí•œ ì˜ˆì™¸ ì ìš©: {cleaned_text[:100]}...")

        # ICAO ê³µí•­ ì½”ë“œ ì¶”ì¶œ (ë” ìœ ì—°í•œ íŒ¨í„´)
        # ì˜ˆ: 28JUN25 00:00 - 25SEP25 23:59 LOWW A1483/25
        # ì˜ˆ: 19SEP25 08:46 - UFN LOWW A2268/25
        # ì˜ˆ: 24MAR23 16:00 - UFN RKRR CHINA SUP 16/21
        # ì˜ˆ: 1. 20FEB25 00:00 - UFN RKSI COAD01/25
        # 'ê³µí•­ì½”ë“œ (AIP SUP) NOTAMë²ˆí˜¸' í˜•ì‹ë„ ì¸ì‹í•˜ë„ë¡ ì •ê·œì‹ ë³´ì™„
        airport_match = re.search(r'(?:\d+\.\s+)?\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN)\s+([A-Z]{4})(?:\s+(?:AIP\s+SUP|CHINA\s+SUP|COAD))?\s+[A-Z0-9]+/\d{2}', cleaned_text)
        if airport_match:
            parsed_notam['airport_code'] = airport_match.group(1)
        else:
            # ë³´ì™„ íŒ¨í„´: ë” ì¼ë°˜ì ì¸ 4ìë¦¬ ê³µí•­ ì½”ë“œ íŒ¨í„´ (AIP SUP, CHINA SUP, COAD í¬í•¨)
            airport_fallback = re.search(r'\b([A-Z]{4})(?:\s+(?:AIP\s+SUP|CHINA\s+SUP|COAD))?\s+[A-Z0-9]+/\d{2}', cleaned_text)
            if airport_fallback:
                parsed_notam['airport_code'] = airport_fallback.group(1)
            else:
                # COAD íŒ¨í„´ ì§ì ‘ ë§¤ì¹­
                coad_airport_match = re.search(r'([A-Z]{4})\s+COAD\d{2}/\d{2}', cleaned_text)
                if coad_airport_match:
                    parsed_notam['airport_code'] = coad_airport_match.group(1)
                else:
                    # ì‹¤ì œ COAD NOTAMì¸ì§€ í™•ì¸ (ì‹œê°„ ì •ë³´ê°€ ìˆëŠ”ì§€ ì²´í¬)
                    has_time_pattern = re.search(r'\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN)', cleaned_text)
                    # COADê°€ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ ì‹œê°„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ëŠ” fakeì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                    # í•˜ì§€ë§Œ ë„ˆë¬´ ì—„ê²©í•˜ì§€ ì•Šê²Œ ìˆ˜ì • (ê¸¸ì´ ì œí•œì„ ë” í¬ê²Œ)
                    if 'coad' in cleaned_text.lower() and not has_time_pattern and len(cleaned_text) > 800:
                        self.logger.debug(f"ì‹œê°„ ì •ë³´ ì—†ëŠ” ë§¤ìš° ê¸´ COAD ì„¹ì…˜ ê±´ë„ˆë›°ê¸°: {cleaned_text[:100]}...")
                        return {}
                    # E) í˜•ì‹ NOTAM (ê³µí•­ ì´ë¦„ì—ì„œ ì¶”ì¶œ)
                    if cleaned_text.strip().startswith('E)'):
                        # HONG KONG -> VHHH, ë“± ë§¤í•‘ 
                        if 'HONG KONG' in cleaned_text.upper():
                            parsed_notam['airport_code'] = 'VHHH'
                        elif 'INCHEON' in cleaned_text.upper():
                            parsed_notam['airport_code'] = 'RKSI'
                        elif 'GIMPO' in cleaned_text.upper():
                            parsed_notam['airport_code'] = 'RKSS'
                        else:
                            # ê¸°ë³¸ê°’ ì„¤ì •
                            parsed_notam['airport_code'] = 'UNKNOWN'
        
        # NOTAM ë²ˆí˜¸ ì¶”ì¶œ (AIP SUP, CHINA SUP, COAD ë“± ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
        notam_number_match = re.search(r'(?:\d+\.\s+)?\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN)\s+[A-Z]{4}(?:\s+(?:AIP\s+SUP|CHINA\s+SUP|COAD))?\s+([A-Z0-9]+/\d{2})', cleaned_text)
        if notam_number_match:
            # AIP SUPë‚˜ CHINA SUPê°€ ìˆìœ¼ë©´ ì „ì²´ë¥¼ ë¶™ì—¬ì„œ ì‚¬ìš©
            aip_sup_match = re.search(r'(?:\d+\.\s+)?\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN)\s+[A-Z]{4}\s+(AIP\s+SUP|CHINA\s+SUP|COAD)\s+([A-Z0-9]+/\d{2})', cleaned_text)
            if aip_sup_match:
                parsed_notam['notam_number'] = f"{aip_sup_match.group(1)} {aip_sup_match.group(2)}"
            else:
                parsed_notam['notam_number'] = notam_number_match.group(1)
        else:
            # ë³´ì™„ íŒ¨í„´: AIP SUP, CHINA SUP, COAD í¬í•¨ ì¼ë°˜ì ì¸ NOTAM ë²ˆí˜¸ íŒ¨í„´
            notam_fallback = re.search(r'(AIP\s+SUP|CHINA\s+SUP|COAD)\s+([A-Z0-9]+/\d{2})', cleaned_text)
            if notam_fallback:
                parsed_notam['notam_number'] = f"{notam_fallback.group(1)} {notam_fallback.group(2)}"
            else:
                # COAD íŒ¨í„´ ì§ì ‘ ë§¤ì¹­
                coad_match = re.search(r'([A-Z]{4})\s+COAD(\d{2}/\d{2})', cleaned_text)
                if coad_match:
                    parsed_notam['notam_number'] = f"COAD{coad_match.group(2)}"
                else:
                    # ê¸°ì¡´ íŒ¨í„´ë„ ì‹œë„
                    notam_fallback2 = re.search(r'\b([A-Z]\d{4}/\d{2})\b', cleaned_text)
                    if notam_fallback2:
                        parsed_notam['notam_number'] = notam_fallback2.group(1)
        
        # ì‹œê°„ ì •ë³´ íŒŒì‹±
        self._parse_time_info(cleaned_text, parsed_notam)
        
        # D) í•„ë“œ ì¶”ì¶œ (ì‹œê°„ëŒ€ ì •ë³´) - ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ
        lines = cleaned_text.split('\n')
        for i, line in enumerate(lines):
            if line.strip().startswith('D)'):
                d_content = []
                # D) ë‹¤ìŒ ì¤„ë“¤ë„ í¬í•¨
                for j in range(i, len(lines)):
                    if j == i:
                        d_content.append(lines[j].strip()[2:].strip())  # D) ì œê±°
                    elif lines[j].strip() and not lines[j].strip().startswith(('E)', 'F)', 'G)')):
                        d_content.append(lines[j].strip())
                    else:
                        break
                if d_content:
                    parsed_notam['d_field'] = '\n'.join(d_content)
                break
        
        
        # E) í•„ë“œ ì¶”ì¶œ - ë” ìœ ì—°í•œ ì¢…ë£Œ ì¡°ê±´ ì‚¬ìš©
        e_field_match = re.search(r'E\)\s*(.+?)(?=(?:\n|^)\s*={20,}\s*$|(?:\n|^)\s*\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN)\s+[A-Z]{4}|(?:\n|^)\s*=+\s*$|(?:\n|^)={20,}(?:\n|$)|$)', cleaned_text, re.DOTALL)
        if e_field_match:
            e_field = e_field_match.group(1).strip()
            # NO CURRENT NOTAMS FOUND ì´í›„ì˜ ë‚´ìš© ì œê±°
            e_field = re.sub(r'\*{8}\s*NO CURRENT NOTAMS FOUND\s*\*{8}.*$', '', e_field, flags=re.DOTALL | re.IGNORECASE).strip()
            # E) í•„ë“œì— ìƒ‰ìƒ ìŠ¤íƒ€ì¼ ì ìš©
            e_field = apply_color_styles(e_field)
            parsed_notam['e_field'] = e_field
        
        return parsed_notam
    
    def _parse_time_info(self, notam_text, parsed_notam):
        """ì‹œê°„ ì •ë³´ íŒŒì‹± (UFN ì§€ì› í¬í•¨)"""
        
        # 1. UFN (Until Further Notice) íŒ¨í„´ ë¨¼ì € í™•ì¸ (ë²ˆí˜¸ í¬í•¨) - Package 3 NOTAM í˜•ì‹ ì§€ì›
        ufn_pattern = r'(?:\d+\.\s+)?(\d{2}[A-Z]{3}\d{2}) (\d{2}:\d{2}) - UFN(?:\s+[A-Z]{4}(?:\s+[A-Z\s]+/\d{2})?)?'
        ufn_match = re.search(ufn_pattern, notam_text)
        
        if ufn_match:
            start_date, start_time = ufn_match.groups()
            try:
                # ì‹œì‘ ì‹œê°„ íŒŒì‹±
                day = int(start_date[:2])
                month_str = start_date[2:5]
                year = int('20' + start_date[5:7])
                
                month_map = {
                    'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6,
                    'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12
                }
                month = month_map[month_str]
                
                hour, minute = map(int, start_time.split(':'))
                start_dt = datetime(year, month, day, hour, minute)
                
                parsed_notam['effective_time'] = start_dt.strftime('%Y-%m-%dT%H:%M:%SZ')
                parsed_notam['expiry_time'] = 'UFN'
                
                return
                
            except Exception as e:
                print(f"UFN ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜: {e}")
        
        # 2. WEF/TIL íŒ¨í„´ (ë²ˆí˜¸ í¬í•¨) - Package 3 NOTAM í˜•ì‹ ì§€ì›
        wef_til_pattern = r'(?:\d+\.\s+)?(\d{2}[A-Z]{3}\d{2}) (\d{2}:\d{2}) - (\d{2}[A-Z]{3}\d{2}) (\d{2}:\d{2})(?:\s+[A-Z]{4}(?:\s+[A-Z0-9]+/\d{2})?)?'
        wef_til_match = re.search(wef_til_pattern, notam_text)
        
        if wef_til_match:
            start_date, start_time, end_date, end_time = wef_til_match.groups()
            try:
                # ì‹œì‘ ì‹œê°„ íŒŒì‹±
                start_dt = self._parse_datetime_string(start_date, start_time)
                end_dt = self._parse_datetime_string(end_date, end_time)
                
                parsed_notam['effective_time'] = start_dt.strftime('%Y-%m-%dT%H:%M:%SZ')
                parsed_notam['expiry_time'] = end_dt.strftime('%Y-%m-%dT%H:%M:%SZ')
                
                return
                
            except Exception as e:
                print(f"WEF/TIL ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜: {e}")
        
        # 3. B) C) í•„ë“œ íŒ¨í„´
        b_field_match = re.search(r'B\)\s*(\d{10})', notam_text)
        c_field_match = re.search(r'C\)\s*(\d{10})', notam_text)
        
        if b_field_match:
            b_time = b_field_match.group(1)
            try:
                start_dt = self._parse_b_c_time(b_time)
                parsed_notam['effective_time'] = start_dt.strftime('%Y-%m-%dT%H:%M:%SZ')
            except Exception as e:
                print(f"B) í•„ë“œ ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜: {e}")
        
        if c_field_match:
            c_time = c_field_match.group(1)
            try:
                end_dt = self._parse_b_c_time(c_time)
                parsed_notam['expiry_time'] = end_dt.strftime('%Y-%m-%dT%H:%M:%SZ')
            except Exception as e:
                print(f"C) í•„ë“œ ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜: {e}")
    
    def _parse_datetime_string(self, date_str, time_str):
        """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± (30MAY24 01:15 í˜•ì‹)"""
        day = int(date_str[:2])
        month_str = date_str[2:5]
        year = int('20' + date_str[5:7])
        
        month_map = {
            'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6,
            'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12
        }
        month = month_map[month_str]
        
        hour, minute = map(int, time_str.split(':'))
        return datetime(year, month, day, hour, minute)
    
    def _parse_b_c_time(self, time_str):
        """B), C) í•„ë“œ ì‹œê°„ íŒŒì‹± (2503200606 í˜•ì‹)"""
        year = int('20' + time_str[:2])
        month = int(time_str[2:4])
        day = int(time_str[4:6])
        hour = int(time_str[6:8])
        minute = int(time_str[8:10])
        
        return datetime(year, month, day, hour, minute)
    
    def _generate_local_time_display(self, parsed_notam):
        """ë¡œì»¬ ì‹œê°„ í‘œì‹œ ìƒì„±"""
        if not parsed_notam.get('effective_time'):
            return None
        
        airport_code = parsed_notam.get('airport_code', '')
        timezone_offset = self.get_timezone(airport_code)
        
        try:
            # UTC ì‹œê°„ì„ datetime ê°ì²´ë¡œ ë³€í™˜
            effective_dt = datetime.fromisoformat(parsed_notam['effective_time'].replace('Z', '+00:00'))
            
            # íƒ€ì„ì¡´ ì˜¤í”„ì…‹ íŒŒì‹± (+09:00 í˜•ì‹)
            offset_sign = 1 if timezone_offset.startswith('+') else -1
            offset_hours = int(timezone_offset[1:3])
            offset_minutes = int(timezone_offset[4:6])
            offset_delta = timedelta(hours=offset_hours * offset_sign, minutes=offset_minutes * offset_sign)
            
            # ë¡œì»¬ ì‹œê°„ ê³„ì‚°
            local_start = effective_dt + offset_delta
            
            # ë§Œë£Œ ì‹œê°„ ì²˜ë¦¬
            if parsed_notam.get('expiry_time') == 'UFN':
                # UFNì¸ ê²½ìš°
                local_time_str = f"{local_start.strftime('%m/%d %H:%M')} - UFN ({timezone_offset})"
            elif parsed_notam.get('expiry_time'):
                # ì¼ë°˜ì ì¸ ë§Œë£Œ ì‹œê°„ì´ ìˆëŠ” ê²½ìš°
                expiry_dt = datetime.fromisoformat(parsed_notam['expiry_time'].replace('Z', '+00:00'))
                local_end = expiry_dt + offset_delta
                local_time_str = f"{local_start.strftime('%m/%d %H:%M')} - {local_end.strftime('%m/%d %H:%M')} ({timezone_offset})"
            else:
                # ë§Œë£Œ ì‹œê°„ì´ ì—†ëŠ” ê²½ìš°
                local_time_str = f"{local_start.strftime('%m/%d %H:%M')} ({timezone_offset})"
            
            # D) í•„ë“œê°€ ìˆìœ¼ë©´ ì‹œê°„ëŒ€ ì •ë³´ ì¶”ê°€
            if parsed_notam and parsed_notam.get('d_field'):
                d_field = parsed_notam['d_field'].strip()
                # D) í•„ë“œì˜ ì‹œê°„ ì •ë³´ë¥¼ ë¡œì»¬ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                local_d_field = self._convert_d_field_to_local_time(d_field, timezone_offset)
                local_time_str += f" / ì‹œê°„ëŒ€: {local_d_field}({timezone_offset})"
            
            return local_time_str
            
        except Exception as e:
            print(f"ë¡œì»¬ ì‹œê°„ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return None
    
    def format_notam_time_with_local(self, effective_time, expiry_time, airport_code, parsed_notam=None):
        """NOTAM ì‹œê°„ì„ ë¡œì»¬ ì‹œê°„ìœ¼ë¡œ í¬ë§·íŒ…"""
        if not effective_time:
            return None
        
        timezone_offset = self.get_timezone(airport_code)
        
        try:
            # UTC ì‹œê°„ì„ datetime ê°ì²´ë¡œ ë³€í™˜
            effective_dt = datetime.fromisoformat(effective_time.replace('Z', '+00:00'))
            
            # íƒ€ì„ì¡´ ì˜¤í”„ì…‹ íŒŒì‹± (+09:00 í˜•ì‹)
            offset_sign = 1 if timezone_offset.startswith('+') else -1
            offset_hours = int(timezone_offset[1:3])
            offset_minutes = int(timezone_offset[4:6])
            offset_delta = timedelta(hours=offset_hours * offset_sign, minutes=offset_minutes * offset_sign)
            
            # ë¡œì»¬ ì‹œê°„ ê³„ì‚°
            local_start = effective_dt + offset_delta
            
            # ë§Œë£Œ ì‹œê°„ ì²˜ë¦¬
            if expiry_time == 'UFN':
                # UFNì¸ ê²½ìš°
                local_time_str = f"{local_start.strftime('%m/%d %H:%M')} - UFN ({timezone_offset})"
            elif expiry_time:
                # ì¼ë°˜ì ì¸ ë§Œë£Œ ì‹œê°„ì´ ìˆëŠ” ê²½ìš°
                expiry_dt = datetime.fromisoformat(expiry_time.replace('Z', '+00:00'))
                local_end = expiry_dt + offset_delta
                local_time_str = f"{local_start.strftime('%m/%d %H:%M')} - {local_end.strftime('%m/%d %H:%M')} ({timezone_offset})"
            else:
                # ë§Œë£Œ ì‹œê°„ì´ ì—†ëŠ” ê²½ìš°
                local_time_str = f"{local_start.strftime('%m/%d %H:%M')} ({timezone_offset})"
            
            # D) í•„ë“œê°€ ìˆìœ¼ë©´ ì‹œê°„ëŒ€ ì •ë³´ ì¶”ê°€
            if parsed_notam and parsed_notam.get('d_field'):
                d_field = parsed_notam['d_field'].strip()
                # D) í•„ë“œì˜ ì‹œê°„ ì •ë³´ë¥¼ ë¡œì»¬ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                local_d_field = self._convert_d_field_to_local_time(d_field, timezone_offset)
                local_time_str += f" / ì‹œê°„ëŒ€: {local_d_field}({timezone_offset})"
            
            return local_time_str
            
        except Exception as e:
            print(f"ì‹œê°„ í¬ë§·íŒ… ì˜¤ë¥˜: {e}")
            return None
    
    def _convert_d_field_to_local_time(self, d_field, timezone_offset):
        """D) í•„ë“œì˜ ì‹œê°„ì„ ë¡œì»¬ ì‹œê°„ìœ¼ë¡œ ë³€í™˜"""
        try:
            import re
            from datetime import datetime, timedelta
            
            # íƒ€ì„ì¡´ ì˜¤í”„ì…‹ íŒŒì‹± (+07:00 í˜•ì‹)
            offset_sign = 1 if timezone_offset.startswith('+') else -1
            offset_hours = int(timezone_offset[1:3])
            offset_minutes = int(timezone_offset[4:6])
            offset_delta = timedelta(hours=offset_hours * offset_sign, minutes=offset_minutes * offset_sign)
            
            lines = d_field.split('\n')
            converted_lines = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # ë‚ ì§œì™€ ì‹œê°„ íŒ¨í„´ ë§¤ì¹­ (ì˜ˆ: "05 1900-1930", "06-29 1900-2300")
                # ë‹¨ì¼ ë‚ ì§œ íŒ¨í„´: DD HHMM-HHMM
                single_date_match = re.match(r'^(\d{1,2})\s+(\d{4})-(\d{4})$', line)
                if single_date_match:
                    day = int(single_date_match.group(1))
                    start_time = single_date_match.group(2)
                    end_time = single_date_match.group(3)
                    
                    # UTC ì‹œê°„ì„ datetimeìœ¼ë¡œ ë³€í™˜ (2025ë…„ 9ì›” ê¸°ì¤€)
                    utc_start = datetime(2025, 9, day, int(start_time[:2]), int(start_time[2:]))
                    utc_end = datetime(2025, 9, day, int(end_time[:2]), int(end_time[2:]))
                    
                    # ë¡œì»¬ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                    local_start = utc_start + offset_delta
                    local_end = utc_end + offset_delta
                    
                    # ë‚ ì§œê°€ ë°”ë€ŒëŠ” ê²½ìš° ì²˜ë¦¬
                    if local_start.day != day:
                        day_str = f"{local_start.day:02d}"
                    else:
                        day_str = f"{day:02d}"
                    
                    converted_line = f"{day_str} {local_start.strftime('%H%M')}-{local_end.strftime('%H%M')}"
                    converted_lines.append(converted_line)
                    continue
                
                # ë‚ ì§œ ë²”ìœ„ íŒ¨í„´: DD-DD HHMM-HHMM
                date_range_match = re.match(r'^(\d{1,2})-(\d{1,2})\s+(\d{4})-(\d{4})$', line)
                if date_range_match:
                    start_day = int(date_range_match.group(1))
                    end_day = int(date_range_match.group(2))
                    start_time = date_range_match.group(3)
                    end_time = date_range_match.group(4)
                    
                    # UTC ì‹œê°„ì„ datetimeìœ¼ë¡œ ë³€í™˜
                    utc_start = datetime(2025, 9, start_day, int(start_time[:2]), int(start_time[2:]))
                    utc_end = datetime(2025, 9, end_day, int(end_time[:2]), int(end_time[2:]))
                    
                    # ë¡œì»¬ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                    local_start = utc_start + offset_delta
                    local_end = utc_end + offset_delta
                    
                    # ë‚ ì§œ ë²”ìœ„ ë¬¸ìì—´ ìƒì„±
                    if local_start.day != start_day or local_end.day != end_day:
                        converted_line = f"{local_start.day:02d}-{local_end.day:02d} {local_start.strftime('%H%M')}-{local_end.strftime('%H%M')}"
                    else:
                        converted_line = f"{start_day:02d}-{end_day:02d} {local_start.strftime('%H%M')}-{local_end.strftime('%H%M')}"
                    
                    converted_lines.append(converted_line)
                    continue
                
                # ë³€í™˜í•  ìˆ˜ ì—†ëŠ” íŒ¨í„´ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
                converted_lines.append(line)
            
            return '\n'.join(converted_lines)
            
        except Exception as e:
            print(f"D) í•„ë“œ ì‹œê°„ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return d_field  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë°˜í™˜

    def _detect_notam_type(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ NOTAM ìœ í˜•ì„ ê°ì§€ (package or airport)"""
        if 'KOREAN AIR NOTAM PACKAGE' in text.upper():
            return 'package'
        return 'airport'

    def filter_korean_air_notams(self, text):
        """í•œêµ­ í•­ê³µì‚¬ ë…¸ì„  ê´€ë ¨ ëª¨ë“  ê³µí•­ NOTAM ì²˜ë¦¬ (íŒ¨í‚¤ì§€/ê°œë³„ ê³µí•­ ìë™ ê°ì§€)"""
        import re
        
        # NOTAM ìœ í˜• ê°ì§€
        notam_type = self._detect_notam_type(text)
        self.logger.info(f"NOTAM ìœ í˜• ê°ì§€: {notam_type}")
        
        if notam_type == 'package':
            return self._filter_package_notams(text)
        else:
            return self._filter_airport_notams(text)

    def _filter_airport_notams(self, text):
        """ê³µí•­ NOTAM í•„í„°ë§ (ê¸°ì¡´ ë¡œì§)"""
        import re
        
        # ë” ìœ ì—°í•œ NOTAM ì‹œì‘ íŒ¨í„´ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›, SECY ì œì™¸, ë²ˆí˜¸ í¬í•¨)
        notam_start_patterns = [
            r'^(?:\d+\.\s+)?\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}(?!\s+SECY)',  # ë²ˆí˜¸ í¬í•¨ íŒ¨í„´ (SECY ì œì™¸)
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}(?!\s+SECY)',  # ê¸°ì¡´ íŒ¨í„´ (SECY ì œì™¸)
            r'^(?:\d+\.\s+)?\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}\s+(?!SECY)[A-Z0-9]+/\d{2}',  # ë²ˆí˜¸ í¬í•¨ NOTAM ë²ˆí˜¸ íŒ¨í„´ (SECY ì œì™¸)
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}\s+(?!SECY)[A-Z0-9]+/\d{2}',  # NOTAM ë²ˆí˜¸ í¬í•¨ (SECY ì œì™¸)
            r'^(?:\d+\.\s+)?\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}\s+AIP\s+SUP\s+\d{2}/\d{2}',  # ë²ˆí˜¸ í¬í•¨ AIP SUP í˜•ì‹
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}\s+AIP\s+SUP\s+\d{2}/\d{2}',  # AIP SUP í˜•ì‹
            r'^[A-Z]{4}\s+COAD\d{2}/\d{2}$',  # VVCR COAD01/25 í˜•ì‹
        ]
        section_end_patterns = [
            r'^\[ALTN\]', r'^\[DEST\]', r'^\[ENRT\]', r'^\[ETC\]', r'^\[INFO\]', r'^\[ROUTE\]', r'^\[WX\]',
            r'^COAD',
            r'^[A-Z]{4} COAD\d{2}/\d{2}',
            r'^[A-Z]{4}\s*$',  # ê³µí•­ì½”ë“œë§Œ ë‹¨ë… ë“±ì¥
            r'^1\.\s+RUNWAY\s*:',  # "1. RUNWAY :" íŒ¨í„´ ì¶”ê°€
            r'^={4,}$'  # 4ê°œ ì´ìƒì˜ ë“±í˜¸ë¡œë§Œ êµ¬ì„±ëœ ì¤„ (NOTAM êµ¬ë¶„ì„ )
        ]
        
        # ê¸°ì¡´ ê³µí•­ NOTAM í•„í„°ë§ ë¡œì§
        lines = text.split('\n')
        notam_sections = []
        current_notam = []
        found_first_notam = False
        skip_mode = False
        
        for line in lines:
            # skip_modeê°€ Trueì¼ ë•ŒëŠ” ìƒˆë¡œìš´ NOTAM ì‹œì‘ íŒ¨í„´ë§Œ ì²˜ë¦¬í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ëª¨ë‘ ê±´ë„ˆë›°ê¸°
            if skip_mode:
                # ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„
                if any(re.match(pattern, line) for pattern in notam_start_patterns):
                    found_first_notam = True
                    skip_mode = False
                    if current_notam:
                        notam_sections.append('\n'.join(current_notam).strip())
                        current_notam = []
                    current_notam.append(line)
                    self.logger.debug(f"ìƒˆë¡œìš´ NOTAM ì‹œì‘ìœ¼ë¡œ skip_mode í•´ì œ: {line.strip()[:50]}...")
                # skip_modeê°€ Trueë©´ ì–´ë–¤ ì¤„ë„ current_notamì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                continue
            
            # END OF KOREAN AIR NOTAM PACKAGE ì²˜ë¦¬ - í˜„ì¬ NOTAMì„ ì¢…ë£Œí•˜ê³  END OF KOREAN AIR NOTAM PACKAGE ì´í›„ ëª¨ë“  ë‚´ìš© ê±´ë„ˆë›°ê¸°
            if re.search(r'END OF KOREAN AIR NOTAM PACKAGE', line.strip(), re.IGNORECASE):
                if current_notam:
                    notam_sections.append('\n'.join(current_notam).strip())
                    self.logger.debug(f"END OF KOREAN AIR NOTAM PACKAGEë¡œ NOTAM ì¢…ë£Œ: {len(current_notam)}ì¤„")
                    current_notam = []
                # END OF KOREAN AIR NOTAM PACKAGE ì´í›„ ëª¨ë“  ë‚´ìš©ì„ ê±´ë„ˆë›°ê¸° ìœ„í•´ skip_mode í™œì„±í™”
                skip_mode = True
                self.logger.debug(f"END OF KOREAN AIR NOTAM PACKAGE ì´í›„ ê±´ë„ˆë›°ê¸° ì‹œì‘")
                # END OF KOREAN AIR NOTAM PACKAGE ë¼ì¸ ìì²´ë„ current_notamì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                continue
                
            # NO CURRENT NOTAMS FOUND ì²˜ë¦¬ - í˜„ì¬ NOTAMì„ ì¢…ë£Œí•˜ê³  ì´í›„ ëª¨ë“  ë‚´ìš© ê±´ë„ˆë›°ê¸°
            if re.search(r'\*{8}\s*NO CURRENT NOTAMS FOUND\s*\*{8}', line.strip(), re.IGNORECASE):
                if current_notam:
                    notam_sections.append('\n'.join(current_notam).strip())
                    self.logger.debug(f"NO CURRENT NOTAMS FOUNDë¡œ NOTAM ì¢…ë£Œ: {len(current_notam)}ì¤„")
                    current_notam = []
                # NO CURRENT NOTAMS FOUND ì´í›„ ëª¨ë“  ë‚´ìš©ì„ ê±´ë„ˆë›°ê¸° ìœ„í•´ skip_mode í™œì„±í™”
                skip_mode = True
                self.logger.debug(f"NO CURRENT NOTAMS FOUND ì´í›„ ê±´ë„ˆë›°ê¸° ì‹œì‘")
                # NO CURRENT NOTAMS FOUND ë¼ì¸ ìì²´ë„ current_notamì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                continue
                
            # SECY ê´€ë ¨ íŒ¨í„´ ì™„ì „ ì œì™¸
            if (re.search(r'SECY\s*/\s*SECURITY INFORMATION', line.strip(), re.IGNORECASE) or
                re.search(r'SECY\s+COAD\d+/\d+', line.strip(), re.IGNORECASE) or
                re.search(r'\d+\.\s+\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s+SECY', line.strip(), re.IGNORECASE)):
                # SECY ì„¹ì…˜ ì „ì²´ë¥¼ ê±´ë„ˆë›°ê¸° ìœ„í•´ skip_mode í™œì„±í™”
                skip_mode = True
                self.logger.debug(f"SECY ê´€ë ¨ íŒ¨í„´ ê±´ë„ˆë›°ê¸° ì‹œì‘: {line.strip()}")
                continue
                
            # COMPANY ADVISORY ì„¹ì…˜ ì™„ì „ ì œì™¸ - ëª¨ë“  COMPANY ADVISORY ê´€ë ¨ ë‚´ìš© ê±´ë„ˆë›°ê¸°
            if re.search(r'COMPANY ADVISORY|MPANY ADVISORY', line.strip(), re.IGNORECASE):
                # COMPANY ADVISORY ì„¹ì…˜ ì „ì²´ë¥¼ ê±´ë„ˆë›°ê¸° ìœ„í•´ skip_mode í™œì„±í™”
                skip_mode = True
                self.logger.debug(f"COMPANY ADVISORY ì„¹ì…˜ ê±´ë„ˆë›°ê¸° ì‹œì‘: {line.strip()}")
                continue
                
            # SECY ì„¹ì…˜ ë‚´ ê°œë³„ í•­ëª©ë“¤ë„ ê±´ë„ˆë›°ê¸° (1., 2., 3. ë“±)
            if re.search(r'^\d+\.\s+\d{2}[A-Z]{3}\d{2}', line.strip()) and skip_mode:
                self.logger.debug(f"SECY/COMPANY ADVISORY í•­ëª© ê±´ë„ˆë›°ê¸°: {line.strip()[:50]}...")
                continue
                
            # COMPANY ADVISORY í•­ëª© ì¢…ë£Œ íŒ¨í„´ì—ì„œ skip_mode í•´ì œ
            if re.search(r'--\s+BY\s+[A-Z]+--', line.strip()) and skip_mode:
                self.logger.debug(f"COMPANY ADVISORY ì„¹ì…˜ ê±´ë„ˆë›°ê¸° ì¢…ë£Œ")
                skip_mode = False
                continue
                
            # COMPANY ADVISORY ì„¹ì…˜ì—ì„œ ìƒˆë¡œìš´ NOTAMì´ ì‹œì‘ë˜ë©´ skip_mode í•´ì œ
            # ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„í•˜ì—¬ NOTAM ì‹œì‘ í™•ì¸
            notam_start_found = any(re.match(pattern, line) for pattern in notam_start_patterns)
            
            if notam_start_found and skip_mode:
                self.logger.debug(f"ìƒˆë¡œìš´ NOTAM ì‹œì‘ìœ¼ë¡œ COMPANY ADVISORY skip_mode í•´ì œ")
                skip_mode = False
                found_first_notam = True
                if current_notam:
                    notam_sections.append('\n'.join(current_notam).strip())
                    current_notam = []
                current_notam.append(line)
                continue
                
            if notam_start_found:
                found_first_notam = True
                skip_mode = False
                if current_notam:
                    notam_sections.append('\n'.join(current_notam).strip())
                    self.logger.debug(f"ìƒˆ NOTAM ì‹œì‘ìœ¼ë¡œ ì´ì „ NOTAM ì¢…ë£Œ: {len(current_notam)}ì¤„")
                    current_notam = []
                current_notam.append(line)
                self.logger.debug(f"ìƒˆ NOTAM ì‹œì‘: {line.strip()[:50]}...")
            elif any(re.match(pat, line) for pat in section_end_patterns):
                if current_notam:
                    notam_sections.append('\n'.join(current_notam).strip())
                    current_notam = []
                skip_mode = True
            elif found_first_notam:
                current_notam.append(line)
                
        if current_notam:
            notam_sections.append('\n'.join(current_notam).strip())

        filtered_notams = []
        self.logger.info(f"ì´ {len(notam_sections)}ê°œì˜ NOTAM ì„¹ì…˜ìœ¼ë¡œ ë¶„í• ë¨")

        for i, section in enumerate(notam_sections):
            section = section.strip()
            if not section:
                continue

            # NOTAM íŒŒì‹±
            parsed_notam = self._parse_notam_section(section)

            self.logger.debug(f"ì„¹ì…˜ {i+1}: ê³µí•­ì½”ë“œ={parsed_notam.get('airport_code')}, NOTAMë²ˆí˜¸={parsed_notam.get('notam_number')}")

            # ê³µí•­ ì½”ë“œê°€ ìˆëŠ” ëª¨ë“  NOTAM ì²˜ë¦¬ (í•œêµ­ ê³µí•­ì´ ì•„ë‹ˆì–´ë„ í¬í•¨)
            if parsed_notam.get('airport_code'):
                # ê¸°ë³¸ ì •ë³´ ì„¤ì •
                # COAD NOTAMì˜ ê²½ìš° E) í•„ë“œê°€ ì—†ìœ¼ë¯€ë¡œ ì „ì²´ ì„¹ì…˜ì„ descriptionìœ¼ë¡œ ì‚¬ìš©
                description = parsed_notam.get('e_field') or section
                
                # E ì„¹ì…˜ë§Œ ì›ë¬¸ìœ¼ë¡œ ì‚¬ìš© (D ì„¹ì…˜ ì œì™¸)
                e_field_content = extract_e_section(section)
                if not e_field_content:
                    # E ì„¹ì…˜ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ parsed_notamì˜ e_field ì‚¬ìš©
                    e_field_content = parsed_notam.get('e_field', '')
                    if not e_field_content:
                        e_field_content = description  # ê·¸ë˜ë„ ì—†ìœ¼ë©´ description ì‚¬ìš©
                
                # ì›ë¬¸ì—ë„ ìƒ‰ìƒ ìŠ¤íƒ€ì¼ ì ìš©
                styled_section = apply_color_styles(e_field_content)
                
                # NOTAM ì¹´í…Œê³ ë¦¬ ë¶„ì„
                category = analyze_notam_category(e_field_content, parsed_notam.get('q_code'))
                category_info = NOTAM_CATEGORIES.get(category, {
                    'icon': 'ğŸ“„',
                    'color': '#6c757d',
                    'bg_color': '#e9ecef'
                })
                
                notam_dict = {
                    'id': parsed_notam.get('notam_number', 'Unknown'),
                    'notam_number': parsed_notam.get('notam_number', 'Unknown'),
                    'airport_code': parsed_notam.get('airport_code'),
                    'effective_time': parsed_notam.get('effective_time', ''),
                    'expiry_time': parsed_notam.get('expiry_time', ''),
                    'description': description,
                    'original_text': styled_section,
                    'd_field': parsed_notam.get('d_field', ''),
                    'e_field': parsed_notam.get('e_field', ''),
                    'category': category,
                    'category_icon': category_info['icon'],
                    'category_color': category_info['color'],
                    'category_bg_color': category_info['bg_color']
                }

                # UFNì„ í¬í•¨í•œ ëª¨ë“  ì‹œê°„ ì •ë³´ì— ëŒ€í•´ local_time_display ìƒì„±
                if parsed_notam.get('effective_time') and (parsed_notam.get('expiry_time') or parsed_notam.get('expiry_time') == 'UFN'):
                    local_time_display = self._generate_local_time_display(parsed_notam)
                    if local_time_display:
                        notam_dict['local_time_display'] = local_time_display
                        # ì›ë³¸ í…ìŠ¤íŠ¸ì—ëŠ” ë¡œì»¬ ì‹œê°„ ì¶”ê°€í•˜ì§€ ì•ŠìŒ (ë³„ë„ í•„ë“œë¡œ ê´€ë¦¬)

                filtered_notams.append(notam_dict)
            else:
                self.logger.warning(f"ì„¹ì…˜ {i+1}: ê³µí•­ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (ì„¹ì…˜ ì‹œì‘: {section[:100]}...)")

        self.logger.info(f"ìµœì¢… {len(filtered_notams)}ê°œì˜ NOTAM ì¶”ì¶œ ì™„ë£Œ")
        return filtered_notams
    
    def _extract_content_after_notam_number(self, text, notam_number):
        """NOTAM ë²ˆí˜¸ ì´í›„ì˜ ë‚´ìš©ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        self.logger.info(f"ğŸ” ì›ë¬¸ ì¶”ì¶œ ì‹œì‘ - NOTAM: {notam_number}")
        self.logger.info(f"ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
        
        if not notam_number:
            self.logger.warning("âš ï¸ NOTAM ë²ˆí˜¸ê°€ ì—†ì–´ì„œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜")
            return text
        
        # NOTAM ë²ˆí˜¸ë¥¼ ì°¾ì•„ì„œ ê·¸ ì´í›„ì˜ ë‚´ìš©ì„ ì¶”ì¶œ
        # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ NOTAM ë²ˆí˜¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤
        patterns = [
            # COAD íŒ¨í„´: RKSI COAD01/25
            rf'([A-Z]{{4}}\s+)?{re.escape(notam_number)}',
            # AIP SUP íŒ¨í„´: AIP SUP 20/25
            rf'(AIP\s+SUP\s+)?{re.escape(notam_number)}',
            # ì¼ë°˜ íŒ¨í„´: A1234/25
            rf'\b{re.escape(notam_number)}\b'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                # NOTAM ë²ˆí˜¸ ì´í›„ì˜ ë‚´ìš© ì¶”ì¶œ
                after_notam = text[match.end():].strip()
                
                # // ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° // ì œê±°
                if after_notam.startswith('//'):
                    after_notam = after_notam[2:].strip()
                
                # -- BYë¡œ ëë‚˜ëŠ” ê²½ìš° ê·¸ ì´í›„ ì œê±°
                by_match = re.search(r'--\s*BY\s+[A-Z]+--', after_notam)
                if by_match:
                    after_notam = after_notam[:by_match.start()].strip()
                
                self.logger.info(f"âœ… ì²« ë²ˆì§¸ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ ì„±ê³µ: {len(after_notam)}ì")
                return after_notam
        
        # íŒ¨í„´ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, ë” ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ ì‹œë„
        # NOTAM ë²ˆí˜¸ë§Œìœ¼ë¡œ ì§ì ‘ ì°¾ê¸°
        simple_patterns = [
            rf'{re.escape(notam_number)}\s*//',  # COAD01/25 //
            rf'{re.escape(notam_number)}\s+//',  # COAD01/25 //
            rf'{re.escape(notam_number)}\s*$',   # ì¤„ ëì— ìˆëŠ” ê²½ìš°
        ]
        
        for pattern in simple_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                after_notam = text[match.end():].strip()
                if after_notam.startswith('//'):
                    after_notam = after_notam[2:].strip()
                
                by_match = re.search(r'--\s*BY\s+[A-Z]+--', after_notam)
                if by_match:
                    after_notam = after_notam[:by_match.start()].strip()
                
                self.logger.info(f"âœ… ê°„ë‹¨í•œ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ ì„±ê³µ: {len(after_notam)}ì")
                return after_notam
        
        # ëª¨ë“  íŒ¨í„´ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
        self.logger.warning(f"âŒ íŒ¨í„´ì„ ì°¾ì§€ ëª»í•´ì„œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜")
        return text

    def _filter_package_notams(self, text):
        """íŒ¨í‚¤ì§€ NOTAM í•„í„°ë§ (pdf_to_txt_test_package.py ê¸°ë°˜)"""
        import re
        
        # íŒ¨í‚¤ì§€ NOTAMì˜ ë³µì¡í•œ êµ¬ì¡°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¡œì§
        # ë¨¼ì € ë¼ì¸ ë³‘í•© ì²˜ë¦¬
        merged_text = self._merge_package_notam_lines(text)
        
        # NOTAM ë¶„ë¦¬
        notam_sections = self._split_package_notams(merged_text)
        
        filtered_notams = []
        self.logger.info(f"íŒ¨í‚¤ì§€ NOTAM ì´ {len(notam_sections)}ê°œì˜ ì„¹ì…˜ìœ¼ë¡œ ë¶„í• ë¨")

        for i, section in enumerate(notam_sections):
            section = section.strip()
            if not section:
                continue

            # NOTAM íŒŒì‹±
            parsed_notam = self._parse_notam_section(section)

            self.logger.debug(f"íŒ¨í‚¤ì§€ ì„¹ì…˜ {i+1}: ê³µí•­ì½”ë“œ={parsed_notam.get('airport_code')}, NOTAMë²ˆí˜¸={parsed_notam.get('notam_number')}")

            # ê³µí•­ ì½”ë“œê°€ ìˆëŠ” ëª¨ë“  NOTAM ì²˜ë¦¬
            if parsed_notam.get('airport_code'):
                # ê¸°ë³¸ ì •ë³´ ì„¤ì •
                # ì›ë¬¸ì—ì„œ NOTAM ë²ˆí˜¸ ì´í›„ì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
                original_content = self._extract_content_after_notam_number(section, parsed_notam.get('notam_number', ''))
                self.logger.debug(f"ì›ë¬¸ ì¶”ì¶œ - NOTAM: {parsed_notam.get('notam_number')}, ì›ë³¸ ê¸¸ì´: {len(section)}, ì¶”ì¶œëœ ê¸¸ì´: {len(original_content)}")
                styled_original = apply_color_styles(original_content)
                
                # NOTAM ì¹´í…Œê³ ë¦¬ ë¶„ì„
                category = analyze_notam_category(original_content, parsed_notam.get('q_code'))
                category_info = NOTAM_CATEGORIES.get(category, {
                    'icon': 'ğŸ“„',
                    'color': '#6c757d',
                    'bg_color': '#e9ecef'
                })
                
                notam_dict = {
                    'id': parsed_notam.get('notam_number', 'Unknown'),
                    'notam_number': parsed_notam.get('notam_number', 'Unknown'),
                    'airport_code': parsed_notam.get('airport_code'),
                    'effective_time': parsed_notam.get('effective_time', ''),
                    'expiry_time': parsed_notam.get('expiry_time', ''),
                    'description': parsed_notam.get('e_field', section),
                    'original_text': styled_original,
                    'd_field': parsed_notam.get('d_field', ''),
                    'category': category,
                    'category_icon': category_info['icon'],
                    'category_color': category_info['color'],
                    'category_bg_color': category_info['bg_color']
                }

                # UFNì„ í¬í•¨í•œ ëª¨ë“  ì‹œê°„ ì •ë³´ì— ëŒ€í•´ local_time_display ìƒì„±
                if parsed_notam.get('effective_time') and (parsed_notam.get('expiry_time') or parsed_notam.get('expiry_time') == 'UFN'):
                    local_time_display = self._generate_local_time_display(parsed_notam)
                    if local_time_display:
                        notam_dict['local_time_display'] = local_time_display
                        # ì›ë³¸ í…ìŠ¤íŠ¸ì—ëŠ” ë¡œì»¬ ì‹œê°„ ì¶”ê°€í•˜ì§€ ì•ŠìŒ (ë³„ë„ í•„ë“œë¡œ ê´€ë¦¬)

                filtered_notams.append(notam_dict)
            else:
                self.logger.warning(f"íŒ¨í‚¤ì§€ ì„¹ì…˜ {i+1}: ê³µí•­ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (ì„¹ì…˜ ì‹œì‘: {section[:100]}...)")

        # íŒ¨í‚¤ì§€ íƒ€ì… ê°ì§€ ë° ê³µí•­ ìˆœì„œ ì •ë ¬
        package_type = self._detect_package_type(text)
        if package_type:
            self.logger.info(f"íŒ¨í‚¤ì§€ íƒ€ì… ê°ì§€: {package_type}")
            # ê³µí•­ ìˆœì„œì— ë”°ë¼ ì •ë ¬
            filtered_notams.sort(key=lambda x: self._get_airport_priority(x.get('airport_code', ''), package_type))
            self.logger.info(f"íŒ¨í‚¤ì§€ë³„ ê³µí•­ ìˆœì„œë¡œ ì •ë ¬ ì™„ë£Œ: {package_type}")
            
            # ì •ë ¬ í›„ ìˆœì„œ ë¡œê¹…
            self.logger.info("=== íŒ¨í‚¤ì§€ë³„ ê³µí•­ ìˆœì„œë¡œ ì •ë ¬ëœ NOTAM ===")
            for i, notam in enumerate(filtered_notams[:10], 1):  # ì²« 10ê°œë§Œ ë¡œê¹…
                airport = notam.get('airport_code', 'N/A')
                notam_num = notam.get('notam_number', 'N/A')
                priority = self._get_airport_priority(airport, package_type)
                self.logger.info(f"ì •ë ¬ í›„ {i}: {airport} {notam_num} (ìš°ì„ ìˆœìœ„: {priority})")
        else:
            self.logger.warning("íŒ¨í‚¤ì§€ íƒ€ì…ì„ ê°ì§€í•  ìˆ˜ ì—†ìŒ - ì›ë³¸ ìˆœì„œ ìœ ì§€")
        
        self.logger.info(f"íŒ¨í‚¤ì§€ NOTAM ìµœì¢… {len(filtered_notams)}ê°œì˜ NOTAM ì¶”ì¶œ ì™„ë£Œ")
        return filtered_notams

    def extract_package_airports(self, text, all_airports):
        """PDF í…ìŠ¤íŠ¸ì—ì„œ Packageë³„ ê³µí•­ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ìˆœì„œë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •"""
        import re
        
        package_airports = {}
        
        # Package 1 ì •ë³´ ì¶”ì¶œ - DEP, DEST, ALTN ë¼ì¸ì—ì„œ ê³µí•­ ì½”ë“œ ì¶”ì¶œ
        package1_airports = []
        
        # DEP ë¼ì¸ì—ì„œ ê³µí•­ ì½”ë“œ ì¶”ì¶œ
        dep_match = re.search(r'DEP:\s*([A-Z]{4})', text)
        if dep_match:
            package1_airports.append(dep_match.group(1))
        
        # DEST ë¼ì¸ì—ì„œ ê³µí•­ ì½”ë“œ ì¶”ì¶œ
        dest_match = re.search(r'DEST:\s*([A-Z]{4})', text)
        if dest_match:
            package1_airports.append(dest_match.group(1))
        
        # ALTN ë¼ì¸ì—ì„œ ê³µí•­ ì½”ë“œ ì¶”ì¶œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
        altn_match = re.search(r'ALTN:\s*([A-Z\s]+?)(?=\n|$)', text)
        if altn_match:
            altn_airports = re.findall(r'[A-Z]{4}', altn_match.group(1))
            package1_airports.extend(altn_airports)
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê³µí•­ë§Œ í•„í„°ë§ (ì¶”ì¶œí•œ ìˆœì„œ ìœ ì§€)
        existing_package1 = [airport for airport in package1_airports if airport in all_airports]
        
        # Package 1 ì •ì˜ìƒ í¬í•¨ë˜ì–´ì•¼ í•˜ëŠ” ê³µí•­ë“¤ ì¤‘ ëˆ„ë½ëœ ê²ƒ ì¶”ê°€ (ìˆœì„œ ìœ ì§€)
        expected_package1 = ['RKSI', 'VVDN', 'VVCR']
        for airport in expected_package1:
            if airport in package1_airports and airport not in existing_package1:
                existing_package1.append(airport)
                
        if existing_package1:
            package_airports['package1'] = existing_package1
            # ë™ì ìœ¼ë¡œ ì¶”ì¶œëœ ìˆœì„œë¡œ package_airport_order ì—…ë°ì´íŠ¸
            self.package_airport_order['package1'] = existing_package1
        
        # Package 2 ì •ë³´ ì¶”ì¶œ - ë‹¤ì–‘í•œ ERA íŒ¨í„´ì—ì„œ ê³µí•­ ì½”ë“œ ì¶”ì¶œ
        package2_airports = []
        
        # ë‹¤ì–‘í•œ ERA íŒ¨í„´ë“¤ ì²˜ë¦¬ (3% ERA, 5% ERA, ERA ë“±)
        era_patterns = [
            r'\d+%\s*ERA:\s*([A-Z\s]+?)(?=\n[A-Z]{2,}:\s*|\n=+|\n\[|$)',  # 3% ERA, 5% ERA ë“±
            r'ERA:\s*([A-Z\s]+?)(?=\n[A-Z]{2,}:\s*|\n=+|\n\[|$)'  # ì¼ë°˜ ERA
        ]
        
        for pattern in era_patterns:
            era_matches = re.findall(pattern, text, re.DOTALL)
            for era_match in era_matches:
                era_airports = re.findall(r'[A-Z]{4}', era_match)
                package2_airports.extend(era_airports)
        
        # REFILE ë¼ì¸ì—ì„œ ê³µí•­ ì½”ë“œ ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)
        refile_match = re.search(r'REFILE:\s*([A-Z\s]+?)(?=\n[A-Z]{2,}:\s*|\n=+|\n\[|$)', text, re.DOTALL)
        if refile_match:
            refile_airports = re.findall(r'[A-Z]{4}', refile_match.group(1))
            package2_airports.extend(refile_airports)
        
        # EDTO ë¼ì¸ì—ì„œ ê³µí•­ ì½”ë“œ ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)
        edto_match = re.search(r'EDTO:\s*([A-Z\s]+?)(?=\n[A-Z]{2,}:\s*|\n=+|\n\[|$)', text, re.DOTALL)
        if edto_match:
            edto_airports = re.findall(r'[A-Z]{4}', edto_match.group(1))
            package2_airports.extend(edto_airports)
        
        # ì¤‘ë³µ ì œê±° ë° ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê³µí•­ë§Œ í•„í„°ë§ (ì¶”ì¶œí•œ ìˆœì„œ ìœ ì§€)
        package2_airports = list(set(package2_airports))
        existing_package2 = [airport for airport in package2_airports if airport in all_airports]
        if existing_package2:
            package_airports['package2'] = existing_package2
            # ë™ì ìœ¼ë¡œ ì¶”ì¶œëœ ìˆœì„œë¡œ package_airport_order ì—…ë°ì´íŠ¸
            self.package_airport_order['package2'] = existing_package2
        
        # Package 3 ì •ë³´ ì¶”ì¶œ - FIR ë¼ì¸ì—ì„œ ê³µí•­ ì½”ë“œ ì¶”ì¶œ
        package3_airports = []
        
        # FIR ë¼ì¸ì—ì„œ ê³µí•­ ì½”ë“œ ì¶”ì¶œ
        fir_match = re.search(r'FIR:\s*([A-Z\s]+?)(?=\n[A-Z]{2,}:\s*|\n=+|\n\[|$)', text, re.DOTALL)
        if fir_match:
            fir_airports = re.findall(r'[A-Z]{4}', fir_match.group(1))
            package3_airports.extend(fir_airports)
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê³µí•­ë§Œ í•„í„°ë§ (ì¶”ì¶œí•œ ìˆœì„œ ìœ ì§€)
        existing_package3 = [airport for airport in package3_airports if airport in all_airports]
        if existing_package3:
            package_airports['package3'] = existing_package3
            # ë™ì ìœ¼ë¡œ ì¶”ì¶œëœ ìˆœì„œë¡œ package_airport_order ì—…ë°ì´íŠ¸
            self.package_airport_order['package3'] = existing_package3
        
        self.logger.info(f"ì¶”ì¶œëœ Packageë³„ ê³µí•­ (ë™ì  ìˆœì„œ): {package_airports}")
        self.logger.info(f"ì—…ë°ì´íŠ¸ëœ package_airport_order: {self.package_airport_order}")
        return package_airports

    def _merge_package_notam_lines(self, text):
        """íŒ¨í‚¤ì§€ NOTAM ë¼ì¸ ë³‘í•© (pdf_to_txt_test_package.py ê¸°ë°˜)"""
        lines = text.split('\n')
        
        # ì‚­ì œí•  í‚¤ì›Œë“œ ëª©ë¡ (OCR ì˜¤ë¥˜ íŒ¨í„´ í¬í•¨)
        unwanted_keywords = [
            'Ã¢â€”RÂ¼A MP', 'Ã¢â€”OÂ¼B STRUCTION', 'Ã¢â€”GÂ¼P S', 'Ã¢â€”RÂ¼U NWAY', 'Ã¢â€”AÂ¼PP ROACH', 'Ã¢â€”TÂ¼A XIWAY',
            'Ã¢â€”NÂ¼A VAID', 'Ã¢â€”DÂ¼E PARTURE', 'Ã¢â€”RÂ¼U NWAY LIGHT', 'Ã¢â€”AÂ¼IP', 'Ã¢â€”OÂ¼T HER'
        ]
        
        # ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì¤„ ì‚­ì œ
        filtered_lines = [line for line in lines if not any(keyword in line for keyword in unwanted_keywords)]
        
        merged_lines = []
        i = 0
        
        # ë” ì •í™•í•œ íŒ¨í„´ë“¤
        notam_id_pattern = r'^[A-Z]{4}(?:\s+[A-Z]+(?:\s+[A-Z]+)*)?\s+\d{1,3}/\d{2}$|^[A-Z]{4}\s+[A-Z]\d{4}/\d{2}$'
        coad_pattern = r'^[A-Z]{4}\s+COAD\d{2}/\d{2}$'  # COAD íŒ¨í„´ ì¶”ê°€
        date_line_pattern = r'^(?:\d+\.\s+)?\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-'  # "3. " íŒ¨í„´ í¬í•¨
        
        while i < len(filtered_lines):
            line = filtered_lines[i].strip()
            
            # COAD NOTAM ID íŒ¨í„´ ì²´í¬
            if re.match(coad_pattern, line):
                # ë‹¤ìŒ ì¤„ì´ ë‚ ì§œ íŒ¨í„´ì´ë©´ í•©ì¹¨
                if i + 1 < len(filtered_lines) and re.match(date_line_pattern, filtered_lines[i+1].strip()):
                    next_line = filtered_lines[i+1].strip()
                    # "3. " ê°™ì€ ë²ˆí˜¸ ì ‘ë‘ì‚¬ ì œê±°
                    cleaned_date_line = re.sub(r'^\d+\.\s+', '', next_line)
                    merged_lines.append(f"{cleaned_date_line} {line}")
                    i += 2
                    continue
            
            # ì¼ë°˜ NOTAM ID íŒ¨í„´ ì²´í¬
            elif re.match(notam_id_pattern, line):
                # ë‹¤ìŒ ì¤„ì´ ë‚ ì§œ íŒ¨í„´ì´ë©´ í•©ì¹¨
                if i + 1 < len(filtered_lines) and re.match(date_line_pattern, filtered_lines[i+1].strip()):
                    next_line = filtered_lines[i+1].strip()
                    # "3. " ê°™ì€ ë²ˆí˜¸ ì ‘ë‘ì‚¬ ì œê±°
                    cleaned_date_line = re.sub(r'^\d+\.\s+', '', next_line)
                    merged_lines.append(f"{cleaned_date_line} {line}")
                    i += 2
                    continue
            
            merged_lines.append(line)
            i += 1
            
        return '\n'.join(merged_lines)

    def _split_package_notams(self, text):
        """íŒ¨í‚¤ì§€ NOTAMë“¤ì„ ì›ë³¸ í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ì¤„ ìˆœì„œë¡œ ë¶„í• """
        # ì¤„ë²ˆí˜¸ì™€ í•¨ê»˜ ê´€ë¦¬í•˜ì—¬ ì›ë³¸ ORDER ìœ ì§€
        lines_with_index = []
        for i, line in enumerate(text.split('\n'), 1):
            if line.strip():  # ë¹ˆ ì¤„ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                lines_with_index.append((i, line.strip()))
        
        # íŒ¨í„´ ì •ì˜ - ë” ì •í™•í•œ NOTAM ì‹œì‘ íŒ¨í„´ë“¤
        notam_start_pattern = r'^(?:\d+\.\s+)?\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-'
        section_start_pattern = r'^\[.*\]'
        notam_id_pattern = r'^[A-Z]{4}(?:\s+(?!COAD)[A-Z]+)?\s*\d{1,3}/\d{2}$|^[A-Z]{4}\s+[A-Z]\d{4}/\d{2}$'
        coad_pattern = r'^[A-Z]{4}\s+COAD\d{2}/\d{2}$'  # COAD NOTAM íŒ¨í„´ ì¶”ê°€
        aip_ad_pattern = r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:UFN|PERM)\s+[A-Z]{4}\s+AIP\s+AD\s+\d+\.\d+'  # AIP AD íŒ¨í„´ ì¶”ê°€
        
        # ìƒˆë¡œìš´ NOTAM ì‹œì‘ì„ ê°ì§€í•˜ëŠ” ë” ì •í™•í•œ íŒ¨í„´ë“¤
        new_notam_patterns = [
            # COAD íŒ¨í„´ë“¤ - ìˆ«ì ì ‘ë‘ì‚¬ê°€ ìˆëŠ” í˜•ì‹
            r'^\d+\.\s*\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*UFN\s+[A-Z]{4}\s+COAD\d{2}/\d{2}',  # UFN í˜•ì‹
            r'^\d+\.\s*\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*PERM\s+[A-Z]{4}\s+COAD\d{2}/\d{2}',  # PERM í˜•ì‹  
            r'^\d+\.\s*\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s+[A-Z]{4}\s+COAD\d{2}/\d{2}',  # ì˜¨ì „í•œ ë‚ ì§œ í˜•ì‹
            # ì¼ë°˜ NOTAM íŒ¨í„´ë“¤
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}\s+[A-Z]\d{4}/\d{2}',  # ì¼ë°˜ NOTAM - UFN/PERM ì¶”ê°€
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}\s+AIP\s+SUP\s+\d+/\d{2}',  # AIP SUP
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}\s+AIP\s+AD\s+\d+\.\d+',  # AIP AD (ì˜ˆ: AIP AD 2.9)
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}\s+Z\d{4}/\d{2}',  # Z NOTAM
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}|UFN|PERM)\s+[A-Z]{4}\s+COAD\d{2}/\d{2}',  # COAD
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*UFN\s+[A-Z]{4}\s+CHINA\s+SUP\s+\d+/\d{2}',  # CHINA SUP íŒ¨í„´ ì¶”ê°€
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*(?:[A-Z]{3}\d{2}|UFN|PERM)\s+[A-Z]{4}\s+[A-Z]+\d+/\d{2}',  # ë” ì¼ë°˜ì ì¸ íŒ¨í„´ ì¶”ê°€
            r'^\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s*-\s*\d{2}[A-Z]{3}\d{2}\s+\d{2}:\d{2}\s+[A-Z]{4}\s+[A-Z]\d{4}/\d{2}',  # ì—°ì† ë‚ ì§œ íŒ¨í„´
        ]
        
        end_phrase_pattern = r'ANY CHANGE WILL BE NOTIFIED BY NOTAM\.'
        
        # ì„¹ì…˜ ì¢…ë£Œ íŒ¨í„´ë“¤
        section_end_patterns = [
            r'^\[ALTN\]', r'^\[DEST\]', r'^\[ENRT\]', r'^\[ETC\]', r'^\[INFO\]', r'^\[ROUTE\]', r'^\[WX\]',
            r'^COAD',
            r'^[A-Z]{4} COAD\d{2}/\d{2}',
            r'^[A-Z]{4}\s*$',  # ê³µí•­ì½”ë“œë§Œ ë‹¨ë… ë“±ì¥
            r'^1\.\s+RUNWAY\s*:',  # "1. RUNWAY :" íŒ¨í„´ ì¶”ê°€
            r'^={4,}$'  # 4ê°œ ì´ìƒì˜ ë“±í˜¸ë¡œë§Œ êµ¬ì„±ëœ ì¤„ (NOTAM êµ¬ë¶„ì„ )
        ]

        notams_with_index = []
        current_notam_lines = []
        
        for line_num, line in lines_with_index:
            # êµ¬ë¶„ì„  ê°ì§€ (ë¨¼ì € ì²´í¬) - = êµ¬ë¶„ì„ ë§Œ ì‚¬ìš©
            if re.match(r'^={20,}$', line):
                if current_notam_lines:
                    notams_with_index.append((current_notam_lines[0][0], '\n'.join([l[1] for l in current_notam_lines]).strip()))
                    current_notam_lines = []
                continue  # êµ¬ë¶„ì„  ë¼ì¸ì€ ë‹¤ìŒ NOTAMì— í¬í•¨í•˜ì§€ ì•ŠìŒ
            
            # ì„¹ì…˜ ì¢…ë£Œ íŒ¨í„´ ê°ì§€ ([ALTN], "1. RUNWAY :" ë“±)
            if any(re.match(pattern, line.strip()) for pattern in section_end_patterns):
                if current_notam_lines:
                    notams_with_index.append((current_notam_lines[0][0], '\n'.join([l[1] for l in current_notam_lines]).strip()))
                    current_notam_lines = []
                continue  # ì„¹ì…˜ ì¢…ë£Œ ë¼ì¸ì€ ë‹¤ìŒ NOTAMì— í¬í•¨í•˜ì§€ ì•ŠìŒ
            
            # ìƒˆë¡œìš´ NOTAM ì‹œì‘ ê°ì§€ (ë” ì •í™•í•œ íŒ¨í„´ ì‚¬ìš©)
            is_new_notam = False
            for pattern in new_notam_patterns:
                if re.match(pattern, line.strip()):
                    is_new_notam = True
                    break
            
            # AIP AD íŒ¨í„´ë„ ì²´í¬
            if not is_new_notam and re.match(aip_ad_pattern, line.strip()):
                is_new_notam = True
            
            if is_new_notam:
                # í˜„ì¬ NOTAMì´ ìˆìœ¼ë©´ ì €ì¥í•˜ê³  ìƒˆë¡œ ì‹œì‘
                if current_notam_lines:
                    notams_with_index.append((current_notam_lines[0][0], '\n'.join([l[1] for l in current_notam_lines]).strip()))
                current_notam_lines = [(line_num, line)]
            else:
                current_notam_lines.append((line_num, line))
                
            # ë ë¬¸êµ¬ ë“±ì¥ ì‹œ ê°•ì œ ëŠê¸°
            if re.search(end_phrase_pattern, line):
                if current_notam_lines:
                    notams_with_index.append((current_notam_lines[0][0], '\n'.join([l[1] for l in current_notam_lines]).strip()))
                    current_notam_lines = []
                
        if current_notam_lines:
            notams_with_index.append((current_notam_lines[0][0], '\n'.join([l[1] for l in current_notam_lines]).strip()))
        
        # ì¤„ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì›ë³¸ í…ìŠ¤íŠ¸ ìˆœì„œ ì—„ê²©íˆ ìœ ì§€
        notams_with_index.sort(key=lambda x: x[0])
        
        # ë¡œê¹…ìœ¼ë¡œ ìˆœì„œ í™•ì¸ (ë””ë²„ê¹…ìš©)
        self.logger.info("=== ì›ë³¸ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆœì„œë¡œ NOTAM ì •ë ¬ ===")
        for i, (line_num, notam_text) in enumerate(notams_with_index[:10], 1):  # ì²« 10ê°œë§Œ ë¡œê¹…
            coad_match = re.search(r'COAD\d+/\d+', notam_text)
            coad_number = coad_match.group(0) if coad_match else "N/A"
            notam_type = "RKSI" if "RKSI" in notam_text else ""
            self.logger.info(f"ì¤„ {line_num}: NOTAM {i} -> {notam_type} {coad_number}")
            
        return [notam_text for _, notam_text in notams_with_index]